{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avinash Singh 2011MC04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Conclusion: Dataset is Free From NaN Values '"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" Conclusion: Dataset is Free From NaN Values \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the Input Features and Target Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Outcome', 1)\n",
    "y = df[['Outcome']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding of the Target Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnTransformer = ColumnTransformer([('encoder',OneHotEncoder(),[0])],remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(columnTransformer.fit_transform(y), dtype = np.str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  \n",
       "2                     0.672   32  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 2)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building kernel_regularizer, bias_regularizer and activity_regularizer in both Hidden layers and set to l1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 154 samples\n",
      "Epoch 1/1000\n",
      "614/614 [==============================] - 1s 1ms/step - loss: 2.4114 - accuracy: 0.6205 - val_loss: 2.0297 - val_accuracy: 0.6883\n",
      "Epoch 2/1000\n",
      "614/614 [==============================] - 0s 293us/step - loss: 1.9532 - accuracy: 0.6466 - val_loss: 1.6702 - val_accuracy: 0.6623\n",
      "Epoch 3/1000\n",
      "614/614 [==============================] - 0s 298us/step - loss: 1.5932 - accuracy: 0.6433 - val_loss: 1.3647 - val_accuracy: 0.6623\n",
      "Epoch 4/1000\n",
      "614/614 [==============================] - 0s 293us/step - loss: 1.2980 - accuracy: 0.6450 - val_loss: 1.1167 - val_accuracy: 0.6623\n",
      "Epoch 5/1000\n",
      "614/614 [==============================] - 0s 316us/step - loss: 1.0703 - accuracy: 0.6433 - val_loss: 0.9395 - val_accuracy: 0.6623\n",
      "Epoch 6/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.9163 - accuracy: 0.6466 - val_loss: 0.8254 - val_accuracy: 0.6558\n",
      "Epoch 7/1000\n",
      "614/614 [==============================] - 0s 282us/step - loss: 0.8235 - accuracy: 0.6450 - val_loss: 0.7641 - val_accuracy: 0.6558\n",
      "Epoch 8/1000\n",
      "614/614 [==============================] - 0s 313us/step - loss: 0.7763 - accuracy: 0.6450 - val_loss: 0.7332 - val_accuracy: 0.6558\n",
      "Epoch 9/1000\n",
      "614/614 [==============================] - 0s 330us/step - loss: 0.7438 - accuracy: 0.6498 - val_loss: 0.7032 - val_accuracy: 0.6494\n",
      "Epoch 10/1000\n",
      "614/614 [==============================] - 0s 304us/step - loss: 0.7199 - accuracy: 0.6466 - val_loss: 0.6808 - val_accuracy: 0.6558\n",
      "Epoch 11/1000\n",
      "614/614 [==============================] - 0s 313us/step - loss: 0.6963 - accuracy: 0.6482 - val_loss: 0.6580 - val_accuracy: 0.6623\n",
      "Epoch 12/1000\n",
      "614/614 [==============================] - 0s 320us/step - loss: 0.6744 - accuracy: 0.6417 - val_loss: 0.6379 - val_accuracy: 0.6623\n",
      "Epoch 13/1000\n",
      "614/614 [==============================] - 0s 272us/step - loss: 0.6550 - accuracy: 0.6433 - val_loss: 0.6199 - val_accuracy: 0.6623\n",
      "Epoch 14/1000\n",
      "614/614 [==============================] - 0s 277us/step - loss: 0.6355 - accuracy: 0.6466 - val_loss: 0.6015 - val_accuracy: 0.6623\n",
      "Epoch 15/1000\n",
      "614/614 [==============================] - 0s 281us/step - loss: 0.6185 - accuracy: 0.6450 - val_loss: 0.5859 - val_accuracy: 0.6623\n",
      "Epoch 16/1000\n",
      "614/614 [==============================] - 0s 297us/step - loss: 0.6027 - accuracy: 0.6466 - val_loss: 0.5718 - val_accuracy: 0.6623\n",
      "Epoch 17/1000\n",
      "614/614 [==============================] - 0s 294us/step - loss: 0.5882 - accuracy: 0.6466 - val_loss: 0.5586 - val_accuracy: 0.6623\n",
      "Epoch 18/1000\n",
      "614/614 [==============================] - 0s 297us/step - loss: 0.5749 - accuracy: 0.6450 - val_loss: 0.5469 - val_accuracy: 0.6623\n",
      "Epoch 19/1000\n",
      "614/614 [==============================] - 0s 305us/step - loss: 0.5636 - accuracy: 0.6450 - val_loss: 0.5342 - val_accuracy: 0.6623\n",
      "Epoch 20/1000\n",
      "614/614 [==============================] - 0s 306us/step - loss: 0.5528 - accuracy: 0.6450 - val_loss: 0.5258 - val_accuracy: 0.6753\n",
      "Epoch 21/1000\n",
      "614/614 [==============================] - 0s 288us/step - loss: 0.5414 - accuracy: 0.6466 - val_loss: 0.5137 - val_accuracy: 0.6623\n",
      "Epoch 22/1000\n",
      "614/614 [==============================] - 0s 278us/step - loss: 0.5318 - accuracy: 0.6450 - val_loss: 0.5057 - val_accuracy: 0.6623\n",
      "Epoch 23/1000\n",
      "614/614 [==============================] - 0s 315us/step - loss: 0.5224 - accuracy: 0.6466 - val_loss: 0.4965 - val_accuracy: 0.6623\n",
      "Epoch 24/1000\n",
      "614/614 [==============================] - 0s 304us/step - loss: 0.5139 - accuracy: 0.6450 - val_loss: 0.4879 - val_accuracy: 0.6623\n",
      "Epoch 25/1000\n",
      "614/614 [==============================] - 0s 296us/step - loss: 0.5055 - accuracy: 0.6450 - val_loss: 0.4804 - val_accuracy: 0.6623\n",
      "Epoch 26/1000\n",
      "614/614 [==============================] - 0s 302us/step - loss: 0.4978 - accuracy: 0.6450 - val_loss: 0.4731 - val_accuracy: 0.6623\n",
      "Epoch 27/1000\n",
      "614/614 [==============================] - 0s 310us/step - loss: 0.4907 - accuracy: 0.6433 - val_loss: 0.4666 - val_accuracy: 0.6623\n",
      "Epoch 28/1000\n",
      "614/614 [==============================] - 0s 294us/step - loss: 0.4839 - accuracy: 0.6450 - val_loss: 0.4616 - val_accuracy: 0.6753\n",
      "Epoch 29/1000\n",
      "614/614 [==============================] - 0s 305us/step - loss: 0.4776 - accuracy: 0.6433 - val_loss: 0.4543 - val_accuracy: 0.6623\n",
      "Epoch 30/1000\n",
      "614/614 [==============================] - 0s 316us/step - loss: 0.4715 - accuracy: 0.6498 - val_loss: 0.4490 - val_accuracy: 0.6623\n",
      "Epoch 31/1000\n",
      "614/614 [==============================] - 0s 307us/step - loss: 0.4654 - accuracy: 0.6547 - val_loss: 0.4435 - val_accuracy: 0.6623\n",
      "Epoch 32/1000\n",
      "614/614 [==============================] - 0s 278us/step - loss: 0.4602 - accuracy: 0.6498 - val_loss: 0.4375 - val_accuracy: 0.6623\n",
      "Epoch 33/1000\n",
      "614/614 [==============================] - 0s 300us/step - loss: 0.4545 - accuracy: 0.6466 - val_loss: 0.4333 - val_accuracy: 0.6688\n",
      "Epoch 34/1000\n",
      "614/614 [==============================] - 0s 348us/step - loss: 0.4497 - accuracy: 0.6645 - val_loss: 0.4285 - val_accuracy: 0.6688\n",
      "Epoch 35/1000\n",
      "614/614 [==============================] - 0s 444us/step - loss: 0.4450 - accuracy: 0.6596 - val_loss: 0.4237 - val_accuracy: 0.6688\n",
      "Epoch 36/1000\n",
      "614/614 [==============================] - 0s 430us/step - loss: 0.4407 - accuracy: 0.6645 - val_loss: 0.4195 - val_accuracy: 0.6753\n",
      "Epoch 37/1000\n",
      "614/614 [==============================] - 0s 426us/step - loss: 0.4365 - accuracy: 0.6710 - val_loss: 0.4153 - val_accuracy: 0.6818\n",
      "Epoch 38/1000\n",
      "614/614 [==============================] - 0s 404us/step - loss: 0.4325 - accuracy: 0.6710 - val_loss: 0.4123 - val_accuracy: 0.6948\n",
      "Epoch 39/1000\n",
      "614/614 [==============================] - 0s 341us/step - loss: 0.4292 - accuracy: 0.6661 - val_loss: 0.4087 - val_accuracy: 0.6818\n",
      "Epoch 40/1000\n",
      "614/614 [==============================] - 0s 397us/step - loss: 0.4252 - accuracy: 0.6645 - val_loss: 0.4054 - val_accuracy: 0.6883\n",
      "Epoch 41/1000\n",
      "614/614 [==============================] - 0s 444us/step - loss: 0.4222 - accuracy: 0.6808 - val_loss: 0.4019 - val_accuracy: 0.7078\n",
      "Epoch 42/1000\n",
      "614/614 [==============================] - 0s 314us/step - loss: 0.4186 - accuracy: 0.6759 - val_loss: 0.3985 - val_accuracy: 0.6818\n",
      "Epoch 43/1000\n",
      "614/614 [==============================] - 0s 351us/step - loss: 0.4157 - accuracy: 0.6759 - val_loss: 0.3959 - val_accuracy: 0.7078\n",
      "Epoch 44/1000\n",
      "614/614 [==============================] - 0s 309us/step - loss: 0.4125 - accuracy: 0.6726 - val_loss: 0.3927 - val_accuracy: 0.7013\n",
      "Epoch 45/1000\n",
      "614/614 [==============================] - 0s 319us/step - loss: 0.4103 - accuracy: 0.6824 - val_loss: 0.3920 - val_accuracy: 0.7208\n",
      "Epoch 46/1000\n",
      "614/614 [==============================] - 0s 334us/step - loss: 0.4078 - accuracy: 0.6726 - val_loss: 0.3880 - val_accuracy: 0.6883\n",
      "Epoch 47/1000\n",
      "614/614 [==============================] - 0s 313us/step - loss: 0.4046 - accuracy: 0.6775 - val_loss: 0.3859 - val_accuracy: 0.7078\n",
      "Epoch 48/1000\n",
      "614/614 [==============================] - 0s 329us/step - loss: 0.4022 - accuracy: 0.6889 - val_loss: 0.3839 - val_accuracy: 0.7013\n",
      "Epoch 49/1000\n",
      "614/614 [==============================] - 0s 359us/step - loss: 0.3995 - accuracy: 0.6824 - val_loss: 0.3807 - val_accuracy: 0.7078\n",
      "Epoch 50/1000\n",
      "614/614 [==============================] - 0s 286us/step - loss: 0.3980 - accuracy: 0.6792 - val_loss: 0.3792 - val_accuracy: 0.7078\n",
      "Epoch 51/1000\n",
      "614/614 [==============================] - 0s 324us/step - loss: 0.3955 - accuracy: 0.6889 - val_loss: 0.3802 - val_accuracy: 0.7013\n",
      "Epoch 52/1000\n",
      "614/614 [==============================] - 0s 393us/step - loss: 0.3943 - accuracy: 0.6873 - val_loss: 0.3749 - val_accuracy: 0.7078\n",
      "Epoch 53/1000\n",
      "614/614 [==============================] - 0s 316us/step - loss: 0.3912 - accuracy: 0.6840 - val_loss: 0.3734 - val_accuracy: 0.7273\n",
      "Epoch 54/1000\n",
      "614/614 [==============================] - 0s 276us/step - loss: 0.3897 - accuracy: 0.7020 - val_loss: 0.3723 - val_accuracy: 0.7143\n",
      "Epoch 55/1000\n",
      "614/614 [==============================] - 0s 282us/step - loss: 0.3872 - accuracy: 0.6824 - val_loss: 0.3692 - val_accuracy: 0.7013\n",
      "Epoch 56/1000\n",
      "614/614 [==============================] - 0s 397us/step - loss: 0.3857 - accuracy: 0.6824 - val_loss: 0.3683 - val_accuracy: 0.7013\n",
      "Epoch 57/1000\n",
      "614/614 [==============================] - 0s 437us/step - loss: 0.3837 - accuracy: 0.6922 - val_loss: 0.3663 - val_accuracy: 0.7013\n",
      "Epoch 58/1000\n",
      "614/614 [==============================] - 0s 409us/step - loss: 0.3831 - accuracy: 0.6938 - val_loss: 0.3664 - val_accuracy: 0.7208\n",
      "Epoch 59/1000\n",
      "614/614 [==============================] - 0s 308us/step - loss: 0.3811 - accuracy: 0.6906 - val_loss: 0.3632 - val_accuracy: 0.7013\n",
      "Epoch 60/1000\n",
      "614/614 [==============================] - 0s 378us/step - loss: 0.3797 - accuracy: 0.6824 - val_loss: 0.3630 - val_accuracy: 0.7013\n",
      "Epoch 61/1000\n",
      "614/614 [==============================] - 0s 411us/step - loss: 0.3783 - accuracy: 0.7003 - val_loss: 0.3614 - val_accuracy: 0.7208\n",
      "Epoch 62/1000\n",
      "614/614 [==============================] - 0s 409us/step - loss: 0.3770 - accuracy: 0.6906 - val_loss: 0.3600 - val_accuracy: 0.7078\n",
      "Epoch 63/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.3754 - accuracy: 0.6938 - val_loss: 0.3593 - val_accuracy: 0.7208\n",
      "Epoch 64/1000\n",
      "614/614 [==============================] - 0s 275us/step - loss: 0.3744 - accuracy: 0.6971 - val_loss: 0.3579 - val_accuracy: 0.7208\n",
      "Epoch 65/1000\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.3732 - accuracy: 0.6938 - val_loss: 0.3568 - val_accuracy: 0.7078\n",
      "Epoch 66/1000\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.3721 - accuracy: 0.6922 - val_loss: 0.3565 - val_accuracy: 0.7208\n",
      "Epoch 67/1000\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.3707 - accuracy: 0.6987 - val_loss: 0.3549 - val_accuracy: 0.7273\n",
      "Epoch 68/1000\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.3701 - accuracy: 0.6971 - val_loss: 0.3543 - val_accuracy: 0.7208\n",
      "Epoch 69/1000\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.3694 - accuracy: 0.7020 - val_loss: 0.3538 - val_accuracy: 0.7208\n",
      "Epoch 70/1000\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.3681 - accuracy: 0.6971 - val_loss: 0.3528 - val_accuracy: 0.7273\n",
      "Epoch 71/1000\n",
      "614/614 [==============================] - 0s 383us/step - loss: 0.3673 - accuracy: 0.6987 - val_loss: 0.3512 - val_accuracy: 0.7208\n",
      "Epoch 72/1000\n",
      "614/614 [==============================] - 0s 402us/step - loss: 0.3657 - accuracy: 0.6971 - val_loss: 0.3517 - val_accuracy: 0.7273\n",
      "Epoch 73/1000\n",
      "614/614 [==============================] - 0s 338us/step - loss: 0.3654 - accuracy: 0.7003 - val_loss: 0.3502 - val_accuracy: 0.7273\n",
      "Epoch 74/1000\n",
      "614/614 [==============================] - 0s 345us/step - loss: 0.3645 - accuracy: 0.7020 - val_loss: 0.3489 - val_accuracy: 0.7208\n",
      "Epoch 75/1000\n",
      "614/614 [==============================] - 0s 302us/step - loss: 0.3634 - accuracy: 0.6971 - val_loss: 0.3498 - val_accuracy: 0.7208\n",
      "Epoch 76/1000\n",
      "614/614 [==============================] - 0s 337us/step - loss: 0.3635 - accuracy: 0.7003 - val_loss: 0.3488 - val_accuracy: 0.7143\n",
      "Epoch 77/1000\n",
      "614/614 [==============================] - 0s 299us/step - loss: 0.3622 - accuracy: 0.7020 - val_loss: 0.3471 - val_accuracy: 0.7208\n",
      "Epoch 78/1000\n",
      "614/614 [==============================] - 0s 305us/step - loss: 0.3610 - accuracy: 0.6971 - val_loss: 0.3470 - val_accuracy: 0.7143\n",
      "Epoch 79/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.3612 - accuracy: 0.6971 - val_loss: 0.3464 - val_accuracy: 0.7273\n",
      "Epoch 80/1000\n",
      "614/614 [==============================] - 0s 295us/step - loss: 0.3599 - accuracy: 0.7020 - val_loss: 0.3460 - val_accuracy: 0.7208\n",
      "Epoch 81/1000\n",
      "614/614 [==============================] - 0s 297us/step - loss: 0.3602 - accuracy: 0.6987 - val_loss: 0.3492 - val_accuracy: 0.7013\n",
      "Epoch 82/1000\n",
      "614/614 [==============================] - 0s 270us/step - loss: 0.3592 - accuracy: 0.6971 - val_loss: 0.3452 - val_accuracy: 0.7273\n",
      "Epoch 83/1000\n",
      "614/614 [==============================] - 0s 299us/step - loss: 0.3580 - accuracy: 0.7020 - val_loss: 0.3448 - val_accuracy: 0.7208\n",
      "Epoch 84/1000\n",
      "614/614 [==============================] - 0s 333us/step - loss: 0.3572 - accuracy: 0.7003 - val_loss: 0.3448 - val_accuracy: 0.7143\n",
      "Epoch 85/1000\n",
      "614/614 [==============================] - 0s 386us/step - loss: 0.3567 - accuracy: 0.6971 - val_loss: 0.3442 - val_accuracy: 0.7078\n",
      "Epoch 86/1000\n",
      "614/614 [==============================] - 0s 416us/step - loss: 0.3562 - accuracy: 0.6954 - val_loss: 0.3437 - val_accuracy: 0.7013\n",
      "Epoch 87/1000\n",
      "614/614 [==============================] - 0s 363us/step - loss: 0.3563 - accuracy: 0.6954 - val_loss: 0.3447 - val_accuracy: 0.7078\n",
      "Epoch 88/1000\n",
      "614/614 [==============================] - 0s 402us/step - loss: 0.3563 - accuracy: 0.6922 - val_loss: 0.3434 - val_accuracy: 0.7078\n",
      "Epoch 89/1000\n",
      "614/614 [==============================] - 0s 397us/step - loss: 0.3569 - accuracy: 0.6922 - val_loss: 0.3452 - val_accuracy: 0.7013\n",
      "Epoch 90/1000\n",
      "614/614 [==============================] - 0s 449us/step - loss: 0.3555 - accuracy: 0.6987 - val_loss: 0.3415 - val_accuracy: 0.7208\n",
      "Epoch 91/1000\n",
      "614/614 [==============================] - 0s 433us/step - loss: 0.3541 - accuracy: 0.6971 - val_loss: 0.3420 - val_accuracy: 0.7078\n",
      "Epoch 92/1000\n",
      "614/614 [==============================] - 0s 519us/step - loss: 0.3535 - accuracy: 0.7003 - val_loss: 0.3405 - val_accuracy: 0.7143\n",
      "Epoch 93/1000\n",
      "614/614 [==============================] - 0s 355us/step - loss: 0.3537 - accuracy: 0.6987 - val_loss: 0.3411 - val_accuracy: 0.7208\n",
      "Epoch 94/1000\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.3514 - accuracy: 0.70 - 0s 451us/step - loss: 0.3525 - accuracy: 0.6954 - val_loss: 0.3407 - val_accuracy: 0.7013\n",
      "Epoch 95/1000\n",
      "614/614 [==============================] - 0s 319us/step - loss: 0.3523 - accuracy: 0.6922 - val_loss: 0.3419 - val_accuracy: 0.7013\n",
      "Epoch 96/1000\n",
      "614/614 [==============================] - 0s 333us/step - loss: 0.3519 - accuracy: 0.6938 - val_loss: 0.3408 - val_accuracy: 0.7013\n",
      "Epoch 97/1000\n",
      "614/614 [==============================] - 0s 362us/step - loss: 0.3508 - accuracy: 0.6922 - val_loss: 0.3400 - val_accuracy: 0.7013\n",
      "Epoch 98/1000\n",
      "614/614 [==============================] - 0s 306us/step - loss: 0.3501 - accuracy: 0.6954 - val_loss: 0.3396 - val_accuracy: 0.6948\n",
      "Epoch 99/1000\n",
      "614/614 [==============================] - 0s 353us/step - loss: 0.3501 - accuracy: 0.6922 - val_loss: 0.3393 - val_accuracy: 0.7078\n",
      "Epoch 100/1000\n",
      "614/614 [==============================] - 0s 276us/step - loss: 0.3498 - accuracy: 0.6922 - val_loss: 0.3391 - val_accuracy: 0.7078\n",
      "Epoch 101/1000\n",
      "614/614 [==============================] - 0s 317us/step - loss: 0.3490 - accuracy: 0.7020 - val_loss: 0.3375 - val_accuracy: 0.7013\n",
      "Epoch 102/1000\n",
      "614/614 [==============================] - 0s 449us/step - loss: 0.3492 - accuracy: 0.6889 - val_loss: 0.3398 - val_accuracy: 0.6883\n",
      "Epoch 103/1000\n",
      "614/614 [==============================] - 0s 410us/step - loss: 0.3484 - accuracy: 0.6954 - val_loss: 0.3381 - val_accuracy: 0.7078\n",
      "Epoch 104/1000\n",
      "614/614 [==============================] - 0s 403us/step - loss: 0.3484 - accuracy: 0.6889 - val_loss: 0.3393 - val_accuracy: 0.6883\n",
      "Epoch 105/1000\n",
      "614/614 [==============================] - 0s 273us/step - loss: 0.3507 - accuracy: 0.7052 - val_loss: 0.3393 - val_accuracy: 0.6948\n",
      "Epoch 106/1000\n",
      "614/614 [==============================] - 0s 300us/step - loss: 0.3471 - accuracy: 0.6954 - val_loss: 0.3364 - val_accuracy: 0.7143\n",
      "Epoch 107/1000\n",
      "614/614 [==============================] - 0s 370us/step - loss: 0.3468 - accuracy: 0.6954 - val_loss: 0.3389 - val_accuracy: 0.6948\n",
      "Epoch 108/1000\n",
      "614/614 [==============================] - 0s 380us/step - loss: 0.3473 - accuracy: 0.6971 - val_loss: 0.3363 - val_accuracy: 0.7013\n",
      "Epoch 109/1000\n",
      "614/614 [==============================] - 0s 376us/step - loss: 0.3468 - accuracy: 0.7036 - val_loss: 0.3388 - val_accuracy: 0.6948\n",
      "Epoch 110/1000\n",
      "614/614 [==============================] - 0s 421us/step - loss: 0.3473 - accuracy: 0.6922 - val_loss: 0.3382 - val_accuracy: 0.6948\n",
      "Epoch 111/1000\n",
      "614/614 [==============================] - 0s 316us/step - loss: 0.3471 - accuracy: 0.7085 - val_loss: 0.3372 - val_accuracy: 0.6948\n",
      "Epoch 112/1000\n",
      "614/614 [==============================] - 0s 402us/step - loss: 0.3460 - accuracy: 0.6889 - val_loss: 0.3369 - val_accuracy: 0.6948\n",
      "Epoch 113/1000\n",
      "614/614 [==============================] - 0s 338us/step - loss: 0.3453 - accuracy: 0.7003 - val_loss: 0.3357 - val_accuracy: 0.7013\n",
      "Epoch 114/1000\n",
      "614/614 [==============================] - 0s 381us/step - loss: 0.3455 - accuracy: 0.6922 - val_loss: 0.3378 - val_accuracy: 0.7013\n",
      "Epoch 115/1000\n",
      "614/614 [==============================] - 0s 475us/step - loss: 0.3446 - accuracy: 0.6987 - val_loss: 0.3356 - val_accuracy: 0.6948\n",
      "Epoch 116/1000\n",
      "614/614 [==============================] - 0s 369us/step - loss: 0.3460 - accuracy: 0.6938 - val_loss: 0.3419 - val_accuracy: 0.7013\n",
      "Epoch 117/1000\n",
      "614/614 [==============================] - 0s 284us/step - loss: 0.3466 - accuracy: 0.7036 - val_loss: 0.3358 - val_accuracy: 0.7143\n",
      "Epoch 118/1000\n",
      "614/614 [==============================] - 0s 282us/step - loss: 0.3440 - accuracy: 0.6954 - val_loss: 0.3347 - val_accuracy: 0.7143\n",
      "Epoch 119/1000\n",
      "614/614 [==============================] - 0s 295us/step - loss: 0.3436 - accuracy: 0.7020 - val_loss: 0.3375 - val_accuracy: 0.7013\n",
      "Epoch 120/1000\n",
      "614/614 [==============================] - 0s 292us/step - loss: 0.3423 - accuracy: 0.7036 - val_loss: 0.3346 - val_accuracy: 0.7208\n",
      "Epoch 121/1000\n",
      "614/614 [==============================] - 0s 397us/step - loss: 0.3434 - accuracy: 0.6954 - val_loss: 0.3354 - val_accuracy: 0.6948\n",
      "Epoch 122/1000\n",
      "614/614 [==============================] - 0s 372us/step - loss: 0.3425 - accuracy: 0.7003 - val_loss: 0.3342 - val_accuracy: 0.7143\n",
      "Epoch 123/1000\n",
      "614/614 [==============================] - 0s 324us/step - loss: 0.3422 - accuracy: 0.6954 - val_loss: 0.3341 - val_accuracy: 0.6948\n",
      "Epoch 124/1000\n",
      "614/614 [==============================] - 0s 307us/step - loss: 0.3413 - accuracy: 0.6938 - val_loss: 0.3339 - val_accuracy: 0.6948\n",
      "Epoch 125/1000\n",
      "614/614 [==============================] - 0s 329us/step - loss: 0.3413 - accuracy: 0.6971 - val_loss: 0.3343 - val_accuracy: 0.6883\n",
      "Epoch 126/1000\n",
      "614/614 [==============================] - 0s 326us/step - loss: 0.3408 - accuracy: 0.7036 - val_loss: 0.3349 - val_accuracy: 0.7013\n",
      "Epoch 127/1000\n",
      "614/614 [==============================] - 0s 299us/step - loss: 0.3410 - accuracy: 0.6954 - val_loss: 0.3334 - val_accuracy: 0.7143\n",
      "Epoch 128/1000\n",
      "614/614 [==============================] - 0s 288us/step - loss: 0.3410 - accuracy: 0.7036 - val_loss: 0.3337 - val_accuracy: 0.6818\n",
      "Epoch 129/1000\n",
      "614/614 [==============================] - 0s 318us/step - loss: 0.3405 - accuracy: 0.6971 - val_loss: 0.3364 - val_accuracy: 0.6883\n",
      "Epoch 130/1000\n",
      "614/614 [==============================] - 0s 293us/step - loss: 0.3414 - accuracy: 0.6987 - val_loss: 0.3334 - val_accuracy: 0.7013\n",
      "Epoch 131/1000\n",
      "614/614 [==============================] - 0s 309us/step - loss: 0.3409 - accuracy: 0.7003 - val_loss: 0.3334 - val_accuracy: 0.6883\n",
      "Epoch 132/1000\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.3420 - accuracy: 0.7000 ETA: 0s - loss: 0.3507 - accuracy: 0. - 0s 282us/step - loss: 0.3398 - accuracy: 0.7020 - val_loss: 0.3336 - val_accuracy: 0.7013\n",
      "Epoch 133/1000\n",
      "614/614 [==============================] - 0s 344us/step - loss: 0.3392 - accuracy: 0.6987 - val_loss: 0.3330 - val_accuracy: 0.7013\n",
      "Epoch 134/1000\n",
      "614/614 [==============================] - 0s 326us/step - loss: 0.3388 - accuracy: 0.7068 - val_loss: 0.3343 - val_accuracy: 0.6883\n",
      "Epoch 135/1000\n",
      "614/614 [==============================] - 0s 298us/step - loss: 0.3388 - accuracy: 0.6971 - val_loss: 0.3324 - val_accuracy: 0.6948\n",
      "Epoch 136/1000\n",
      "614/614 [==============================] - 0s 374us/step - loss: 0.3382 - accuracy: 0.7052 - val_loss: 0.3328 - val_accuracy: 0.7078\n",
      "Epoch 137/1000\n",
      "614/614 [==============================] - 0s 401us/step - loss: 0.3392 - accuracy: 0.7036 - val_loss: 0.3321 - val_accuracy: 0.7013\n",
      "Epoch 138/1000\n",
      "614/614 [==============================] - 0s 370us/step - loss: 0.3395 - accuracy: 0.7101 - val_loss: 0.3335 - val_accuracy: 0.6948\n",
      "Epoch 139/1000\n",
      "614/614 [==============================] - 0s 304us/step - loss: 0.3395 - accuracy: 0.7020 - val_loss: 0.3346 - val_accuracy: 0.6948\n",
      "Epoch 140/1000\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.3375 - accuracy: 0.70 - 0s 311us/step - loss: 0.3381 - accuracy: 0.7020 - val_loss: 0.3313 - val_accuracy: 0.7013\n",
      "Epoch 141/1000\n",
      "614/614 [==============================] - 0s 309us/step - loss: 0.3374 - accuracy: 0.7020 - val_loss: 0.3343 - val_accuracy: 0.6883\n",
      "Epoch 142/1000\n",
      "614/614 [==============================] - 0s 389us/step - loss: 0.3374 - accuracy: 0.7020 - val_loss: 0.3310 - val_accuracy: 0.7013\n",
      "Epoch 143/1000\n",
      "614/614 [==============================] - 0s 456us/step - loss: 0.3369 - accuracy: 0.7003 - val_loss: 0.3367 - val_accuracy: 0.6753\n",
      "Epoch 144/1000\n",
      "614/614 [==============================] - 0s 408us/step - loss: 0.3369 - accuracy: 0.7117 - val_loss: 0.3305 - val_accuracy: 0.6948\n",
      "Epoch 145/1000\n",
      "614/614 [==============================] - 0s 480us/step - loss: 0.3368 - accuracy: 0.7020 - val_loss: 0.3366 - val_accuracy: 0.6883\n",
      "Epoch 146/1000\n",
      "614/614 [==============================] - 0s 311us/step - loss: 0.3363 - accuracy: 0.7003 - val_loss: 0.3308 - val_accuracy: 0.7143\n",
      "Epoch 147/1000\n",
      "614/614 [==============================] - 0s 328us/step - loss: 0.3377 - accuracy: 0.7101 - val_loss: 0.3390 - val_accuracy: 0.6688\n",
      "Epoch 148/1000\n",
      "614/614 [==============================] - 0s 438us/step - loss: 0.3371 - accuracy: 0.7248 - val_loss: 0.3298 - val_accuracy: 0.7013\n",
      "Epoch 149/1000\n",
      "614/614 [==============================] - 0s 303us/step - loss: 0.3379 - accuracy: 0.6954 - val_loss: 0.3329 - val_accuracy: 0.6948\n",
      "Epoch 150/1000\n",
      "614/614 [==============================] - 0s 322us/step - loss: 0.3374 - accuracy: 0.7052 - val_loss: 0.3312 - val_accuracy: 0.6948\n",
      "Epoch 151/1000\n",
      "614/614 [==============================] - 0s 346us/step - loss: 0.3367 - accuracy: 0.7036 - val_loss: 0.3323 - val_accuracy: 0.6753\n",
      "Epoch 152/1000\n",
      "614/614 [==============================] - 0s 360us/step - loss: 0.3360 - accuracy: 0.7085 - val_loss: 0.3306 - val_accuracy: 0.7078\n",
      "Epoch 153/1000\n",
      "614/614 [==============================] - 0s 334us/step - loss: 0.3341 - accuracy: 0.7068 - val_loss: 0.3291 - val_accuracy: 0.7078\n",
      "Epoch 154/1000\n",
      "614/614 [==============================] - 0s 376us/step - loss: 0.3343 - accuracy: 0.7052 - val_loss: 0.3291 - val_accuracy: 0.7013\n",
      "Epoch 155/1000\n",
      "614/614 [==============================] - 0s 455us/step - loss: 0.3353 - accuracy: 0.7085 - val_loss: 0.3281 - val_accuracy: 0.7143\n",
      "Epoch 156/1000\n",
      "614/614 [==============================] - 0s 385us/step - loss: 0.3338 - accuracy: 0.7052 - val_loss: 0.3328 - val_accuracy: 0.6883\n",
      "Epoch 157/1000\n",
      "614/614 [==============================] - 0s 316us/step - loss: 0.3339 - accuracy: 0.7085 - val_loss: 0.3281 - val_accuracy: 0.6948\n",
      "Epoch 158/1000\n",
      "614/614 [==============================] - 0s 379us/step - loss: 0.3344 - accuracy: 0.7052 - val_loss: 0.3324 - val_accuracy: 0.6883\n",
      "Epoch 159/1000\n",
      "614/614 [==============================] - 0s 382us/step - loss: 0.3325 - accuracy: 0.7052 - val_loss: 0.3274 - val_accuracy: 0.6948\n",
      "Epoch 160/1000\n",
      "614/614 [==============================] - 0s 363us/step - loss: 0.3340 - accuracy: 0.7068 - val_loss: 0.3342 - val_accuracy: 0.6753\n",
      "Epoch 161/1000\n",
      "614/614 [==============================] - 0s 344us/step - loss: 0.3335 - accuracy: 0.7134 - val_loss: 0.3284 - val_accuracy: 0.7143\n",
      "Epoch 162/1000\n",
      "614/614 [==============================] - 0s 383us/step - loss: 0.3341 - accuracy: 0.7020 - val_loss: 0.3319 - val_accuracy: 0.6753\n",
      "Epoch 163/1000\n",
      "614/614 [==============================] - 0s 321us/step - loss: 0.3324 - accuracy: 0.7134 - val_loss: 0.3262 - val_accuracy: 0.7013\n",
      "Epoch 164/1000\n",
      "614/614 [==============================] - 0s 301us/step - loss: 0.3328 - accuracy: 0.7134 - val_loss: 0.3314 - val_accuracy: 0.6883\n",
      "Epoch 165/1000\n",
      "614/614 [==============================] - 0s 304us/step - loss: 0.3320 - accuracy: 0.7085 - val_loss: 0.3265 - val_accuracy: 0.7078\n",
      "Epoch 166/1000\n",
      "614/614 [==============================] - 0s 298us/step - loss: 0.3311 - accuracy: 0.7052 - val_loss: 0.3262 - val_accuracy: 0.7078\n",
      "Epoch 167/1000\n",
      "614/614 [==============================] - 0s 294us/step - loss: 0.3313 - accuracy: 0.7117 - val_loss: 0.3264 - val_accuracy: 0.7013\n",
      "Epoch 168/1000\n",
      "614/614 [==============================] - 0s 291us/step - loss: 0.3302 - accuracy: 0.7068 - val_loss: 0.3279 - val_accuracy: 0.6818\n",
      "Epoch 169/1000\n",
      "614/614 [==============================] - 0s 283us/step - loss: 0.3306 - accuracy: 0.7166 - val_loss: 0.3267 - val_accuracy: 0.6818\n",
      "Epoch 170/1000\n",
      "614/614 [==============================] - 0s 317us/step - loss: 0.3299 - accuracy: 0.7150 - val_loss: 0.3260 - val_accuracy: 0.6883\n",
      "Epoch 171/1000\n",
      "614/614 [==============================] - 0s 288us/step - loss: 0.3296 - accuracy: 0.7150 - val_loss: 0.3290 - val_accuracy: 0.6818\n",
      "Epoch 172/1000\n",
      "614/614 [==============================] - 0s 308us/step - loss: 0.3318 - accuracy: 0.7215 - val_loss: 0.3277 - val_accuracy: 0.7143\n",
      "Epoch 173/1000\n",
      "614/614 [==============================] - 0s 304us/step - loss: 0.3295 - accuracy: 0.7166 - val_loss: 0.3278 - val_accuracy: 0.6883\n",
      "Epoch 174/1000\n",
      "614/614 [==============================] - 0s 281us/step - loss: 0.3295 - accuracy: 0.7182 - val_loss: 0.3268 - val_accuracy: 0.6753\n",
      "Epoch 175/1000\n",
      "614/614 [==============================] - 0s 330us/step - loss: 0.3283 - accuracy: 0.7231 - val_loss: 0.3244 - val_accuracy: 0.7273\n",
      "Epoch 176/1000\n",
      "614/614 [==============================] - 0s 296us/step - loss: 0.3287 - accuracy: 0.7231 - val_loss: 0.3262 - val_accuracy: 0.6948\n",
      "Epoch 177/1000\n",
      "614/614 [==============================] - 0s 287us/step - loss: 0.3280 - accuracy: 0.7296 - val_loss: 0.3243 - val_accuracy: 0.7143\n",
      "Epoch 178/1000\n",
      "614/614 [==============================] - 0s 317us/step - loss: 0.3279 - accuracy: 0.7231 - val_loss: 0.3255 - val_accuracy: 0.7078\n",
      "Epoch 179/1000\n",
      "614/614 [==============================] - 0s 306us/step - loss: 0.3280 - accuracy: 0.7264 - val_loss: 0.3253 - val_accuracy: 0.6883\n",
      "Epoch 180/1000\n",
      "614/614 [==============================] - 0s 301us/step - loss: 0.3286 - accuracy: 0.7280 - val_loss: 0.3282 - val_accuracy: 0.6883\n",
      "Epoch 181/1000\n",
      "614/614 [==============================] - 0s 324us/step - loss: 0.3283 - accuracy: 0.7362 - val_loss: 0.3237 - val_accuracy: 0.7013\n",
      "Epoch 182/1000\n",
      "614/614 [==============================] - 0s 286us/step - loss: 0.3296 - accuracy: 0.7182 - val_loss: 0.3306 - val_accuracy: 0.6818\n",
      "Epoch 183/1000\n",
      "614/614 [==============================] - 0s 299us/step - loss: 0.3288 - accuracy: 0.7264 - val_loss: 0.3229 - val_accuracy: 0.7273\n",
      "Epoch 184/1000\n",
      "614/614 [==============================] - 0s 294us/step - loss: 0.3273 - accuracy: 0.7248 - val_loss: 0.3234 - val_accuracy: 0.7013\n",
      "Epoch 185/1000\n",
      "614/614 [==============================] - 0s 363us/step - loss: 0.3267 - accuracy: 0.7313 - val_loss: 0.3260 - val_accuracy: 0.6948\n",
      "Epoch 186/1000\n",
      "614/614 [==============================] - 0s 286us/step - loss: 0.3271 - accuracy: 0.7215 - val_loss: 0.3268 - val_accuracy: 0.6818\n",
      "Epoch 187/1000\n",
      "614/614 [==============================] - 0s 328us/step - loss: 0.3281 - accuracy: 0.7215 - val_loss: 0.3227 - val_accuracy: 0.7208\n",
      "Epoch 188/1000\n",
      "614/614 [==============================] - 0s 324us/step - loss: 0.3268 - accuracy: 0.7362 - val_loss: 0.3256 - val_accuracy: 0.6883\n",
      "Epoch 189/1000\n",
      "614/614 [==============================] - 0s 306us/step - loss: 0.3249 - accuracy: 0.7248 - val_loss: 0.3205 - val_accuracy: 0.7273\n",
      "Epoch 190/1000\n",
      "614/614 [==============================] - 0s 310us/step - loss: 0.3284 - accuracy: 0.7231 - val_loss: 0.3263 - val_accuracy: 0.6883\n",
      "Epoch 191/1000\n",
      "614/614 [==============================] - 0s 289us/step - loss: 0.3266 - accuracy: 0.7345 - val_loss: 0.3249 - val_accuracy: 0.6948\n",
      "Epoch 192/1000\n",
      "614/614 [==============================] - 0s 272us/step - loss: 0.3251 - accuracy: 0.7313 - val_loss: 0.3215 - val_accuracy: 0.7208\n",
      "Epoch 193/1000\n",
      "614/614 [==============================] - 0s 287us/step - loss: 0.3263 - accuracy: 0.7248 - val_loss: 0.3305 - val_accuracy: 0.6818\n",
      "Epoch 194/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.3255 - accuracy: 0.7378 - val_loss: 0.3203 - val_accuracy: 0.7273\n",
      "Epoch 195/1000\n",
      "614/614 [==============================] - 0s 300us/step - loss: 0.3261 - accuracy: 0.7280 - val_loss: 0.3276 - val_accuracy: 0.6883\n",
      "Epoch 196/1000\n",
      "614/614 [==============================] - 0s 298us/step - loss: 0.3261 - accuracy: 0.7313 - val_loss: 0.3200 - val_accuracy: 0.7338\n",
      "Epoch 197/1000\n",
      "614/614 [==============================] - 0s 337us/step - loss: 0.3254 - accuracy: 0.7345 - val_loss: 0.3213 - val_accuracy: 0.6883\n",
      "Epoch 198/1000\n",
      "614/614 [==============================] - 0s 294us/step - loss: 0.3269 - accuracy: 0.7134 - val_loss: 0.3287 - val_accuracy: 0.6883\n",
      "Epoch 199/1000\n",
      "614/614 [==============================] - 0s 282us/step - loss: 0.3248 - accuracy: 0.7329 - val_loss: 0.3209 - val_accuracy: 0.7273\n",
      "Epoch 200/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.3243 - accuracy: 0.7264 - val_loss: 0.3229 - val_accuracy: 0.6883\n",
      "Epoch 201/1000\n",
      "614/614 [==============================] - 0s 304us/step - loss: 0.3243 - accuracy: 0.7459 - val_loss: 0.3200 - val_accuracy: 0.7013\n",
      "Epoch 202/1000\n",
      "614/614 [==============================] - 0s 298us/step - loss: 0.3228 - accuracy: 0.7199 - val_loss: 0.3215 - val_accuracy: 0.6883\n",
      "Epoch 203/1000\n",
      "614/614 [==============================] - 0s 289us/step - loss: 0.3217 - accuracy: 0.7394 - val_loss: 0.3210 - val_accuracy: 0.7143\n",
      "Epoch 204/1000\n",
      "614/614 [==============================] - 0s 286us/step - loss: 0.3233 - accuracy: 0.7264 - val_loss: 0.3250 - val_accuracy: 0.6818\n",
      "Epoch 205/1000\n",
      "614/614 [==============================] - 0s 287us/step - loss: 0.3216 - accuracy: 0.7410 - val_loss: 0.3181 - val_accuracy: 0.7078\n",
      "Epoch 206/1000\n",
      "614/614 [==============================] - 0s 302us/step - loss: 0.3212 - accuracy: 0.7329 - val_loss: 0.3181 - val_accuracy: 0.7078\n",
      "Epoch 207/1000\n",
      "614/614 [==============================] - 0s 287us/step - loss: 0.3217 - accuracy: 0.7313 - val_loss: 0.3245 - val_accuracy: 0.6753\n",
      "Epoch 208/1000\n",
      "614/614 [==============================] - 0s 301us/step - loss: 0.3209 - accuracy: 0.7394 - val_loss: 0.3188 - val_accuracy: 0.7078\n",
      "Epoch 209/1000\n",
      "614/614 [==============================] - 0s 308us/step - loss: 0.3234 - accuracy: 0.7345 - val_loss: 0.3305 - val_accuracy: 0.6818\n",
      "Epoch 210/1000\n",
      "614/614 [==============================] - 0s 320us/step - loss: 0.3244 - accuracy: 0.7410 - val_loss: 0.3170 - val_accuracy: 0.7143\n",
      "Epoch 211/1000\n",
      "614/614 [==============================] - 0s 297us/step - loss: 0.3204 - accuracy: 0.7427 - val_loss: 0.3199 - val_accuracy: 0.7013\n",
      "Epoch 212/1000\n",
      "614/614 [==============================] - 0s 304us/step - loss: 0.3186 - accuracy: 0.7394 - val_loss: 0.3160 - val_accuracy: 0.7143\n",
      "Epoch 213/1000\n",
      "614/614 [==============================] - 0s 296us/step - loss: 0.3201 - accuracy: 0.7459 - val_loss: 0.3163 - val_accuracy: 0.7013\n",
      "Epoch 214/1000\n",
      "614/614 [==============================] - 0s 304us/step - loss: 0.3195 - accuracy: 0.7394 - val_loss: 0.3196 - val_accuracy: 0.7013\n",
      "Epoch 215/1000\n",
      "614/614 [==============================] - 0s 333us/step - loss: 0.3186 - accuracy: 0.7362 - val_loss: 0.3181 - val_accuracy: 0.7013\n",
      "Epoch 216/1000\n",
      "614/614 [==============================] - 0s 332us/step - loss: 0.3182 - accuracy: 0.7410 - val_loss: 0.3158 - val_accuracy: 0.7078\n",
      "Epoch 217/1000\n",
      "614/614 [==============================] - 0s 351us/step - loss: 0.3229 - accuracy: 0.7329 - val_loss: 0.3358 - val_accuracy: 0.6883\n",
      "Epoch 218/1000\n",
      "614/614 [==============================] - 0s 342us/step - loss: 0.3240 - accuracy: 0.7280 - val_loss: 0.3158 - val_accuracy: 0.7338\n",
      "Epoch 219/1000\n",
      "614/614 [==============================] - 0s 325us/step - loss: 0.3209 - accuracy: 0.7296 - val_loss: 0.3221 - val_accuracy: 0.7078\n",
      "Epoch 220/1000\n",
      "614/614 [==============================] - 0s 293us/step - loss: 0.3203 - accuracy: 0.7443 - val_loss: 0.3150 - val_accuracy: 0.7273\n",
      "Epoch 221/1000\n",
      "614/614 [==============================] - 0s 309us/step - loss: 0.3195 - accuracy: 0.7476 - val_loss: 0.3237 - val_accuracy: 0.6753\n",
      "Epoch 222/1000\n",
      "614/614 [==============================] - 0s 288us/step - loss: 0.3193 - accuracy: 0.7378 - val_loss: 0.3153 - val_accuracy: 0.7208\n",
      "Epoch 223/1000\n",
      "614/614 [==============================] - 0s 325us/step - loss: 0.3170 - accuracy: 0.7329 - val_loss: 0.3226 - val_accuracy: 0.6948\n",
      "Epoch 224/1000\n",
      "614/614 [==============================] - 0s 325us/step - loss: 0.3170 - accuracy: 0.7573 - val_loss: 0.3135 - val_accuracy: 0.7208\n",
      "Epoch 225/1000\n",
      "614/614 [==============================] - 0s 319us/step - loss: 0.3185 - accuracy: 0.7476 - val_loss: 0.3172 - val_accuracy: 0.7013\n",
      "Epoch 226/1000\n",
      "614/614 [==============================] - 0s 365us/step - loss: 0.3183 - accuracy: 0.7362 - val_loss: 0.3231 - val_accuracy: 0.6558\n",
      "Epoch 227/1000\n",
      "614/614 [==============================] - 0s 269us/step - loss: 0.3182 - accuracy: 0.7443 - val_loss: 0.3158 - val_accuracy: 0.7013\n",
      "Epoch 228/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.3161 - accuracy: 0.7443 - val_loss: 0.3144 - val_accuracy: 0.7078\n",
      "Epoch 229/1000\n",
      "614/614 [==============================] - 0s 281us/step - loss: 0.3151 - accuracy: 0.7378 - val_loss: 0.3159 - val_accuracy: 0.7013\n",
      "Epoch 230/1000\n",
      "614/614 [==============================] - 0s 293us/step - loss: 0.3150 - accuracy: 0.7459 - val_loss: 0.3147 - val_accuracy: 0.7013\n",
      "Epoch 231/1000\n",
      "614/614 [==============================] - 0s 287us/step - loss: 0.3151 - accuracy: 0.7508 - val_loss: 0.3148 - val_accuracy: 0.7013\n",
      "Epoch 232/1000\n",
      "614/614 [==============================] - 0s 302us/step - loss: 0.3152 - accuracy: 0.7410 - val_loss: 0.3238 - val_accuracy: 0.6948\n",
      "Epoch 233/1000\n",
      "614/614 [==============================] - 0s 273us/step - loss: 0.3162 - accuracy: 0.7655 - val_loss: 0.3129 - val_accuracy: 0.7338\n",
      "Epoch 234/1000\n",
      "614/614 [==============================] - 0s 273us/step - loss: 0.3141 - accuracy: 0.7427 - val_loss: 0.3238 - val_accuracy: 0.7078\n",
      "Epoch 235/1000\n",
      "614/614 [==============================] - 0s 269us/step - loss: 0.3158 - accuracy: 0.7557 - val_loss: 0.3118 - val_accuracy: 0.7208\n",
      "Epoch 236/1000\n",
      "614/614 [==============================] - 0s 273us/step - loss: 0.3191 - accuracy: 0.7378 - val_loss: 0.3203 - val_accuracy: 0.7078\n",
      "Epoch 237/1000\n",
      "614/614 [==============================] - 0s 284us/step - loss: 0.3152 - accuracy: 0.7427 - val_loss: 0.3128 - val_accuracy: 0.7208\n",
      "Epoch 238/1000\n",
      "614/614 [==============================] - 0s 282us/step - loss: 0.3202 - accuracy: 0.7427 - val_loss: 0.3126 - val_accuracy: 0.7143\n",
      "Epoch 239/1000\n",
      "614/614 [==============================] - 0s 280us/step - loss: 0.3141 - accuracy: 0.7280 - val_loss: 0.3184 - val_accuracy: 0.6883\n",
      "Epoch 240/1000\n",
      "614/614 [==============================] - 0s 288us/step - loss: 0.3149 - accuracy: 0.7573 - val_loss: 0.3132 - val_accuracy: 0.7013\n",
      "Epoch 241/1000\n",
      "614/614 [==============================] - 0s 337us/step - loss: 0.3135 - accuracy: 0.7443 - val_loss: 0.3155 - val_accuracy: 0.6948\n",
      "Epoch 242/1000\n",
      "614/614 [==============================] - 0s 336us/step - loss: 0.3161 - accuracy: 0.7590 - val_loss: 0.3115 - val_accuracy: 0.7078\n",
      "Epoch 243/1000\n",
      "614/614 [==============================] - 0s 294us/step - loss: 0.3155 - accuracy: 0.7378 - val_loss: 0.3251 - val_accuracy: 0.6948\n",
      "Epoch 244/1000\n",
      "614/614 [==============================] - 0s 328us/step - loss: 0.3181 - accuracy: 0.7541 - val_loss: 0.3112 - val_accuracy: 0.7338\n",
      "Epoch 245/1000\n",
      "614/614 [==============================] - 0s 283us/step - loss: 0.3149 - accuracy: 0.7427 - val_loss: 0.3152 - val_accuracy: 0.7013\n",
      "Epoch 246/1000\n",
      "614/614 [==============================] - 0s 267us/step - loss: 0.3116 - accuracy: 0.7443 - val_loss: 0.3106 - val_accuracy: 0.7143\n",
      "Epoch 247/1000\n",
      "614/614 [==============================] - 0s 268us/step - loss: 0.3108 - accuracy: 0.7427 - val_loss: 0.3163 - val_accuracy: 0.6948\n",
      "Epoch 248/1000\n",
      "614/614 [==============================] - 0s 292us/step - loss: 0.3117 - accuracy: 0.7557 - val_loss: 0.3110 - val_accuracy: 0.7013\n",
      "Epoch 249/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.3114 - accuracy: 0.7541 - val_loss: 0.3143 - val_accuracy: 0.7078\n",
      "Epoch 250/1000\n",
      "614/614 [==============================] - 0s 278us/step - loss: 0.3113 - accuracy: 0.7655 - val_loss: 0.3096 - val_accuracy: 0.7078\n",
      "Epoch 251/1000\n",
      "614/614 [==============================] - 0s 286us/step - loss: 0.3108 - accuracy: 0.7459 - val_loss: 0.3148 - val_accuracy: 0.7078\n",
      "Epoch 252/1000\n",
      "614/614 [==============================] - 0s 280us/step - loss: 0.3106 - accuracy: 0.7557 - val_loss: 0.3105 - val_accuracy: 0.7143\n",
      "Epoch 253/1000\n",
      "614/614 [==============================] - 0s 277us/step - loss: 0.3101 - accuracy: 0.7524 - val_loss: 0.3132 - val_accuracy: 0.7013\n",
      "Epoch 254/1000\n",
      "614/614 [==============================] - 0s 275us/step - loss: 0.3117 - accuracy: 0.7492 - val_loss: 0.3198 - val_accuracy: 0.7273\n",
      "Epoch 255/1000\n",
      "614/614 [==============================] - 0s 280us/step - loss: 0.3116 - accuracy: 0.7557 - val_loss: 0.3094 - val_accuracy: 0.7143\n",
      "Epoch 256/1000\n",
      "614/614 [==============================] - 0s 280us/step - loss: 0.3099 - accuracy: 0.7476 - val_loss: 0.3141 - val_accuracy: 0.7013\n",
      "Epoch 257/1000\n",
      "614/614 [==============================] - 0s 273us/step - loss: 0.3097 - accuracy: 0.7508 - val_loss: 0.3109 - val_accuracy: 0.6948\n",
      "Epoch 258/1000\n",
      "614/614 [==============================] - 0s 266us/step - loss: 0.3106 - accuracy: 0.7573 - val_loss: 0.3087 - val_accuracy: 0.7013\n",
      "Epoch 259/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.3114 - accuracy: 0.7524 - val_loss: 0.3106 - val_accuracy: 0.6818\n",
      "Epoch 260/1000\n",
      "614/614 [==============================] - 0s 282us/step - loss: 0.3106 - accuracy: 0.7427 - val_loss: 0.3141 - val_accuracy: 0.7143\n",
      "Epoch 261/1000\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.3113 - accuracy: 0.75 - 0s 281us/step - loss: 0.3114 - accuracy: 0.7541 - val_loss: 0.3198 - val_accuracy: 0.7273\n",
      "Epoch 262/1000\n",
      "614/614 [==============================] - 0s 271us/step - loss: 0.3153 - accuracy: 0.7541 - val_loss: 0.3094 - val_accuracy: 0.7208\n",
      "Epoch 263/1000\n",
      "614/614 [==============================] - 0s 280us/step - loss: 0.3090 - accuracy: 0.7541 - val_loss: 0.3144 - val_accuracy: 0.7078\n",
      "Epoch 264/1000\n",
      "614/614 [==============================] - 0s 268us/step - loss: 0.3083 - accuracy: 0.7606 - val_loss: 0.3100 - val_accuracy: 0.6948\n",
      "Epoch 265/1000\n",
      "614/614 [==============================] - 0s 292us/step - loss: 0.3075 - accuracy: 0.7524 - val_loss: 0.3157 - val_accuracy: 0.7143\n",
      "Epoch 266/1000\n",
      "614/614 [==============================] - 0s 255us/step - loss: 0.3072 - accuracy: 0.7606 - val_loss: 0.3073 - val_accuracy: 0.7013\n",
      "Epoch 267/1000\n",
      "614/614 [==============================] - 0s 265us/step - loss: 0.3076 - accuracy: 0.7459 - val_loss: 0.3089 - val_accuracy: 0.7078\n",
      "Epoch 268/1000\n",
      "614/614 [==============================] - 0s 276us/step - loss: 0.3077 - accuracy: 0.7573 - val_loss: 0.3124 - val_accuracy: 0.7143\n",
      "Epoch 269/1000\n",
      "614/614 [==============================] - 0s 260us/step - loss: 0.3071 - accuracy: 0.7524 - val_loss: 0.3111 - val_accuracy: 0.6948\n",
      "Epoch 270/1000\n",
      "614/614 [==============================] - 0s 280us/step - loss: 0.3107 - accuracy: 0.7459 - val_loss: 0.3215 - val_accuracy: 0.7273\n",
      "Epoch 271/1000\n",
      "614/614 [==============================] - 0s 272us/step - loss: 0.3074 - accuracy: 0.7541 - val_loss: 0.3066 - val_accuracy: 0.7013\n",
      "Epoch 272/1000\n",
      "614/614 [==============================] - 0s 279us/step - loss: 0.3076 - accuracy: 0.7476 - val_loss: 0.3091 - val_accuracy: 0.7143\n",
      "Epoch 273/1000\n",
      "614/614 [==============================] - 0s 283us/step - loss: 0.3080 - accuracy: 0.7524 - val_loss: 0.3071 - val_accuracy: 0.7013\n",
      "Epoch 274/1000\n",
      "614/614 [==============================] - 0s 272us/step - loss: 0.3079 - accuracy: 0.7638 - val_loss: 0.3068 - val_accuracy: 0.6948\n",
      "Epoch 275/1000\n",
      "614/614 [==============================] - 0s 276us/step - loss: 0.3059 - accuracy: 0.7541 - val_loss: 0.3111 - val_accuracy: 0.7013\n",
      "Epoch 276/1000\n",
      "614/614 [==============================] - 0s 279us/step - loss: 0.3056 - accuracy: 0.7541 - val_loss: 0.3066 - val_accuracy: 0.7013\n",
      "Epoch 277/1000\n",
      "614/614 [==============================] - 0s 265us/step - loss: 0.3075 - accuracy: 0.7541 - val_loss: 0.3089 - val_accuracy: 0.6948\n",
      "Epoch 278/1000\n",
      "614/614 [==============================] - 0s 278us/step - loss: 0.3063 - accuracy: 0.7492 - val_loss: 0.3100 - val_accuracy: 0.7013\n",
      "Epoch 279/1000\n",
      "614/614 [==============================] - 0s 280us/step - loss: 0.3054 - accuracy: 0.7573 - val_loss: 0.3058 - val_accuracy: 0.7013\n",
      "Epoch 280/1000\n",
      "614/614 [==============================] - 0s 278us/step - loss: 0.3074 - accuracy: 0.7541 - val_loss: 0.3151 - val_accuracy: 0.7273\n",
      "Epoch 281/1000\n",
      "614/614 [==============================] - 0s 294us/step - loss: 0.3062 - accuracy: 0.7476 - val_loss: 0.3085 - val_accuracy: 0.7078\n",
      "Epoch 282/1000\n",
      "614/614 [==============================] - 0s 283us/step - loss: 0.3067 - accuracy: 0.7508 - val_loss: 0.3056 - val_accuracy: 0.7013\n",
      "Epoch 283/1000\n",
      "614/614 [==============================] - 0s 278us/step - loss: 0.3062 - accuracy: 0.7394 - val_loss: 0.3184 - val_accuracy: 0.7143\n",
      "Epoch 284/1000\n",
      "614/614 [==============================] - 0s 272us/step - loss: 0.3048 - accuracy: 0.7671 - val_loss: 0.3053 - val_accuracy: 0.7143\n",
      "Epoch 285/1000\n",
      "614/614 [==============================] - 0s 275us/step - loss: 0.3069 - accuracy: 0.7508 - val_loss: 0.3176 - val_accuracy: 0.7338\n",
      "Epoch 286/1000\n",
      "614/614 [==============================] - 0s 273us/step - loss: 0.3070 - accuracy: 0.7622 - val_loss: 0.3053 - val_accuracy: 0.7013\n",
      "Epoch 287/1000\n",
      "614/614 [==============================] - 0s 301us/step - loss: 0.3048 - accuracy: 0.7508 - val_loss: 0.3064 - val_accuracy: 0.7208\n",
      "Epoch 288/1000\n",
      "614/614 [==============================] - 0s 306us/step - loss: 0.3047 - accuracy: 0.7638 - val_loss: 0.3093 - val_accuracy: 0.7208\n",
      "Epoch 289/1000\n",
      "614/614 [==============================] - 0s 329us/step - loss: 0.3034 - accuracy: 0.7704 - val_loss: 0.3039 - val_accuracy: 0.6948\n",
      "Epoch 290/1000\n",
      "614/614 [==============================] - 0s 327us/step - loss: 0.3051 - accuracy: 0.7736 - val_loss: 0.3095 - val_accuracy: 0.7208\n",
      "Epoch 291/1000\n",
      "614/614 [==============================] - 0s 294us/step - loss: 0.3025 - accuracy: 0.7541 - val_loss: 0.3051 - val_accuracy: 0.7078\n",
      "Epoch 292/1000\n",
      "614/614 [==============================] - 0s 296us/step - loss: 0.3049 - accuracy: 0.7606 - val_loss: 0.3054 - val_accuracy: 0.7143\n",
      "Epoch 293/1000\n",
      "614/614 [==============================] - 0s 284us/step - loss: 0.3027 - accuracy: 0.7541 - val_loss: 0.3105 - val_accuracy: 0.7208\n",
      "Epoch 294/1000\n",
      "614/614 [==============================] - 0s 306us/step - loss: 0.3033 - accuracy: 0.7655 - val_loss: 0.3081 - val_accuracy: 0.7273\n",
      "Epoch 295/1000\n",
      "614/614 [==============================] - 0s 298us/step - loss: 0.3030 - accuracy: 0.7524 - val_loss: 0.3081 - val_accuracy: 0.7338\n",
      "Epoch 296/1000\n",
      "614/614 [==============================] - 0s 301us/step - loss: 0.3030 - accuracy: 0.7655 - val_loss: 0.3042 - val_accuracy: 0.7208\n",
      "Epoch 297/1000\n",
      "614/614 [==============================] - 0s 462us/step - loss: 0.3024 - accuracy: 0.7638 - val_loss: 0.3113 - val_accuracy: 0.7338\n",
      "Epoch 298/1000\n",
      "614/614 [==============================] - 0s 284us/step - loss: 0.3030 - accuracy: 0.7573 - val_loss: 0.3050 - val_accuracy: 0.7273\n",
      "Epoch 299/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.3022 - accuracy: 0.7524 - val_loss: 0.3072 - val_accuracy: 0.7143\n",
      "Epoch 300/1000\n",
      "614/614 [==============================] - 0s 266us/step - loss: 0.3022 - accuracy: 0.7687 - val_loss: 0.3030 - val_accuracy: 0.6883\n",
      "Epoch 301/1000\n",
      "614/614 [==============================] - 0s 289us/step - loss: 0.3016 - accuracy: 0.7557 - val_loss: 0.3086 - val_accuracy: 0.7403\n",
      "Epoch 302/1000\n",
      "614/614 [==============================] - 0s 274us/step - loss: 0.3024 - accuracy: 0.7655 - val_loss: 0.3030 - val_accuracy: 0.7078\n",
      "Epoch 303/1000\n",
      "614/614 [==============================] - 0s 273us/step - loss: 0.3018 - accuracy: 0.7606 - val_loss: 0.3086 - val_accuracy: 0.7338\n",
      "Epoch 304/1000\n",
      "614/614 [==============================] - 0s 265us/step - loss: 0.3012 - accuracy: 0.7638 - val_loss: 0.3053 - val_accuracy: 0.7078\n",
      "Epoch 305/1000\n",
      "614/614 [==============================] - 0s 281us/step - loss: 0.3022 - accuracy: 0.7606 - val_loss: 0.3029 - val_accuracy: 0.7013\n",
      "Epoch 306/1000\n",
      "614/614 [==============================] - 0s 279us/step - loss: 0.3000 - accuracy: 0.7606 - val_loss: 0.3139 - val_accuracy: 0.7273\n",
      "Epoch 307/1000\n",
      "614/614 [==============================] - 0s 262us/step - loss: 0.3032 - accuracy: 0.7573 - val_loss: 0.3023 - val_accuracy: 0.7208\n",
      "Epoch 308/1000\n",
      "614/614 [==============================] - 0s 269us/step - loss: 0.3075 - accuracy: 0.7524 - val_loss: 0.3027 - val_accuracy: 0.7013\n",
      "Epoch 309/1000\n",
      "614/614 [==============================] - 0s 312us/step - loss: 0.3028 - accuracy: 0.7541 - val_loss: 0.3277 - val_accuracy: 0.6883\n",
      "Epoch 310/1000\n",
      "614/614 [==============================] - 0s 277us/step - loss: 0.3093 - accuracy: 0.7476 - val_loss: 0.3044 - val_accuracy: 0.7468\n",
      "Epoch 311/1000\n",
      "614/614 [==============================] - 0s 294us/step - loss: 0.3036 - accuracy: 0.7476 - val_loss: 0.3106 - val_accuracy: 0.7273\n",
      "Epoch 312/1000\n",
      "614/614 [==============================] - 0s 304us/step - loss: 0.3002 - accuracy: 0.7606 - val_loss: 0.3042 - val_accuracy: 0.7013\n",
      "Epoch 313/1000\n",
      "614/614 [==============================] - 0s 335us/step - loss: 0.2995 - accuracy: 0.7508 - val_loss: 0.3196 - val_accuracy: 0.7208\n",
      "Epoch 314/1000\n",
      "614/614 [==============================] - 0s 306us/step - loss: 0.3019 - accuracy: 0.7606 - val_loss: 0.3019 - val_accuracy: 0.7273\n",
      "Epoch 315/1000\n",
      "614/614 [==============================] - 0s 296us/step - loss: 0.3009 - accuracy: 0.7557 - val_loss: 0.3058 - val_accuracy: 0.7208\n",
      "Epoch 316/1000\n",
      "614/614 [==============================] - 0s 294us/step - loss: 0.2997 - accuracy: 0.7655 - val_loss: 0.3042 - val_accuracy: 0.7208\n",
      "Epoch 317/1000\n",
      "614/614 [==============================] - 0s 288us/step - loss: 0.2987 - accuracy: 0.7720 - val_loss: 0.3076 - val_accuracy: 0.7143\n",
      "Epoch 318/1000\n",
      "614/614 [==============================] - 0s 294us/step - loss: 0.2995 - accuracy: 0.7508 - val_loss: 0.3110 - val_accuracy: 0.7338\n",
      "Epoch 319/1000\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.3009 - accuracy: 0.75 - 0s 315us/step - loss: 0.3032 - accuracy: 0.7508 - val_loss: 0.3050 - val_accuracy: 0.7143\n",
      "Epoch 320/1000\n",
      "614/614 [==============================] - 0s 293us/step - loss: 0.2994 - accuracy: 0.7655 - val_loss: 0.3040 - val_accuracy: 0.7078\n",
      "Epoch 321/1000\n",
      "614/614 [==============================] - 0s 299us/step - loss: 0.2983 - accuracy: 0.7606 - val_loss: 0.3071 - val_accuracy: 0.7143\n",
      "Epoch 322/1000\n",
      "614/614 [==============================] - 0s 307us/step - loss: 0.2987 - accuracy: 0.7622 - val_loss: 0.3063 - val_accuracy: 0.7273\n",
      "Epoch 323/1000\n",
      "614/614 [==============================] - 0s 298us/step - loss: 0.2983 - accuracy: 0.7638 - val_loss: 0.3082 - val_accuracy: 0.7338\n",
      "Epoch 324/1000\n",
      "614/614 [==============================] - 0s 311us/step - loss: 0.2982 - accuracy: 0.7638 - val_loss: 0.3081 - val_accuracy: 0.7273\n",
      "Epoch 325/1000\n",
      "614/614 [==============================] - 0s 281us/step - loss: 0.2989 - accuracy: 0.7590 - val_loss: 0.3082 - val_accuracy: 0.7208\n",
      "Epoch 326/1000\n",
      "614/614 [==============================] - 0s 299us/step - loss: 0.2991 - accuracy: 0.7655 - val_loss: 0.3027 - val_accuracy: 0.7338\n",
      "Epoch 327/1000\n",
      "614/614 [==============================] - 0s 283us/step - loss: 0.2985 - accuracy: 0.7508 - val_loss: 0.3126 - val_accuracy: 0.7338\n",
      "Epoch 328/1000\n",
      "614/614 [==============================] - 0s 332us/step - loss: 0.2990 - accuracy: 0.7638 - val_loss: 0.3053 - val_accuracy: 0.7338\n",
      "Epoch 329/1000\n",
      "614/614 [==============================] - 0s 335us/step - loss: 0.2981 - accuracy: 0.7655 - val_loss: 0.3024 - val_accuracy: 0.7273\n",
      "Epoch 330/1000\n",
      "614/614 [==============================] - 0s 307us/step - loss: 0.2982 - accuracy: 0.7508 - val_loss: 0.3080 - val_accuracy: 0.7403\n",
      "Epoch 331/1000\n",
      "614/614 [==============================] - 0s 288us/step - loss: 0.2971 - accuracy: 0.7590 - val_loss: 0.3042 - val_accuracy: 0.7273\n",
      "Epoch 332/1000\n",
      "614/614 [==============================] - 0s 286us/step - loss: 0.2972 - accuracy: 0.7557 - val_loss: 0.3047 - val_accuracy: 0.7208\n",
      "Epoch 333/1000\n",
      "614/614 [==============================] - 0s 281us/step - loss: 0.2967 - accuracy: 0.7638 - val_loss: 0.3062 - val_accuracy: 0.7338\n",
      "Epoch 334/1000\n",
      "614/614 [==============================] - 0s 338us/step - loss: 0.2977 - accuracy: 0.7785 - val_loss: 0.3012 - val_accuracy: 0.7208\n",
      "Epoch 335/1000\n",
      "614/614 [==============================] - 0s 322us/step - loss: 0.2981 - accuracy: 0.7622 - val_loss: 0.3040 - val_accuracy: 0.7403\n",
      "Epoch 336/1000\n",
      "614/614 [==============================] - 0s 341us/step - loss: 0.2964 - accuracy: 0.7655 - val_loss: 0.3014 - val_accuracy: 0.7273\n",
      "Epoch 337/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2998 - accuracy: 0.7524 - val_loss: 0.3065 - val_accuracy: 0.7273\n",
      "Epoch 338/1000\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.2962 - accuracy: 0.7655 - val_loss: 0.3075 - val_accuracy: 0.7273\n",
      "Epoch 339/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2953 - accuracy: 0.7655 - val_loss: 0.3013 - val_accuracy: 0.7208\n",
      "Epoch 340/1000\n",
      "614/614 [==============================] - 0s 263us/step - loss: 0.2959 - accuracy: 0.7671 - val_loss: 0.3046 - val_accuracy: 0.7273\n",
      "Epoch 341/1000\n",
      "614/614 [==============================] - 0s 259us/step - loss: 0.2962 - accuracy: 0.7752 - val_loss: 0.3003 - val_accuracy: 0.7338\n",
      "Epoch 342/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2989 - accuracy: 0.7655 - val_loss: 0.3031 - val_accuracy: 0.7273\n",
      "Epoch 343/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2962 - accuracy: 0.7622 - val_loss: 0.3119 - val_accuracy: 0.7273\n",
      "Epoch 344/1000\n",
      "614/614 [==============================] - 0s 275us/step - loss: 0.2954 - accuracy: 0.7671 - val_loss: 0.3011 - val_accuracy: 0.7273\n",
      "Epoch 345/1000\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.2958 - accuracy: 0.7720 - val_loss: 0.3070 - val_accuracy: 0.7338\n",
      "Epoch 346/1000\n",
      "614/614 [==============================] - 0s 299us/step - loss: 0.2945 - accuracy: 0.7622 - val_loss: 0.3044 - val_accuracy: 0.7403\n",
      "Epoch 347/1000\n",
      "614/614 [==============================] - 0s 255us/step - loss: 0.2955 - accuracy: 0.7557 - val_loss: 0.3011 - val_accuracy: 0.7273\n",
      "Epoch 348/1000\n",
      "614/614 [==============================] - 0s 259us/step - loss: 0.2979 - accuracy: 0.7671 - val_loss: 0.3038 - val_accuracy: 0.7273\n",
      "Epoch 349/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2959 - accuracy: 0.7590 - val_loss: 0.3061 - val_accuracy: 0.7338\n",
      "Epoch 350/1000\n",
      "614/614 [==============================] - 0s 251us/step - loss: 0.2948 - accuracy: 0.7655 - val_loss: 0.3086 - val_accuracy: 0.7208\n",
      "Epoch 351/1000\n",
      "614/614 [==============================] - 0s 277us/step - loss: 0.2966 - accuracy: 0.7655 - val_loss: 0.3095 - val_accuracy: 0.7273\n",
      "Epoch 352/1000\n",
      "614/614 [==============================] - 0s 272us/step - loss: 0.2942 - accuracy: 0.7785 - val_loss: 0.3006 - val_accuracy: 0.7273\n",
      "Epoch 353/1000\n",
      "614/614 [==============================] - 0s 247us/step - loss: 0.2960 - accuracy: 0.7622 - val_loss: 0.3028 - val_accuracy: 0.7273\n",
      "Epoch 354/1000\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.2944 - accuracy: 0.7655 - val_loss: 0.3158 - val_accuracy: 0.7143\n",
      "Epoch 355/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2985 - accuracy: 0.7573 - val_loss: 0.3003 - val_accuracy: 0.7403\n",
      "Epoch 356/1000\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.2961 - accuracy: 0.7573 - val_loss: 0.3097 - val_accuracy: 0.7338\n",
      "Epoch 357/1000\n",
      "614/614 [==============================] - 0s 298us/step - loss: 0.2953 - accuracy: 0.7704 - val_loss: 0.3033 - val_accuracy: 0.7403\n",
      "Epoch 358/1000\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.2948 - accuracy: 0.7736 - val_loss: 0.3028 - val_accuracy: 0.7468\n",
      "Epoch 359/1000\n",
      "614/614 [==============================] - 0s 278us/step - loss: 0.2946 - accuracy: 0.7687 - val_loss: 0.3242 - val_accuracy: 0.7013\n",
      "Epoch 360/1000\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.3008 - accuracy: 0.7638 - val_loss: 0.3011 - val_accuracy: 0.7338\n",
      "Epoch 361/1000\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.2964 - accuracy: 0.7573 - val_loss: 0.3018 - val_accuracy: 0.7273\n",
      "Epoch 362/1000\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.2939 - accuracy: 0.7687 - val_loss: 0.3134 - val_accuracy: 0.7273\n",
      "Epoch 363/1000\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.2946 - accuracy: 0.7769 - val_loss: 0.3020 - val_accuracy: 0.7273\n",
      "Epoch 364/1000\n",
      "614/614 [==============================] - 0s 256us/step - loss: 0.2923 - accuracy: 0.7687 - val_loss: 0.3088 - val_accuracy: 0.7273\n",
      "Epoch 365/1000\n",
      "614/614 [==============================] - 0s 259us/step - loss: 0.2931 - accuracy: 0.7704 - val_loss: 0.3028 - val_accuracy: 0.7208\n",
      "Epoch 366/1000\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.2942 - accuracy: 0.7671 - val_loss: 0.3014 - val_accuracy: 0.7403\n",
      "Epoch 367/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2972 - accuracy: 0.7541 - val_loss: 0.3214 - val_accuracy: 0.7013\n",
      "Epoch 368/1000\n",
      "614/614 [==============================] - 0s 281us/step - loss: 0.2972 - accuracy: 0.7606 - val_loss: 0.3020 - val_accuracy: 0.7338\n",
      "Epoch 369/1000\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.2919 - accuracy: 0.7687 - val_loss: 0.3055 - val_accuracy: 0.7403\n",
      "Epoch 370/1000\n",
      "614/614 [==============================] - 0s 263us/step - loss: 0.2935 - accuracy: 0.7704 - val_loss: 0.3093 - val_accuracy: 0.7403\n",
      "Epoch 371/1000\n",
      "614/614 [==============================] - 0s 269us/step - loss: 0.2912 - accuracy: 0.7704 - val_loss: 0.3004 - val_accuracy: 0.7273\n",
      "Epoch 372/1000\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.2932 - accuracy: 0.7655 - val_loss: 0.3020 - val_accuracy: 0.7273\n",
      "Epoch 373/1000\n",
      "614/614 [==============================] - 0s 243us/step - loss: 0.2920 - accuracy: 0.7638 - val_loss: 0.3057 - val_accuracy: 0.7338\n",
      "Epoch 374/1000\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.2927 - accuracy: 0.7866 - val_loss: 0.2993 - val_accuracy: 0.7468\n",
      "Epoch 375/1000\n",
      "614/614 [==============================] - 0s 236us/step - loss: 0.2983 - accuracy: 0.7492 - val_loss: 0.3242 - val_accuracy: 0.7013\n",
      "Epoch 376/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2955 - accuracy: 0.7655 - val_loss: 0.3031 - val_accuracy: 0.7403\n",
      "Epoch 377/1000\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.2937 - accuracy: 0.7606 - val_loss: 0.3009 - val_accuracy: 0.7338\n",
      "Epoch 378/1000\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.2937 - accuracy: 0.7606 - val_loss: 0.3165 - val_accuracy: 0.7273\n",
      "Epoch 379/1000\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.2942 - accuracy: 0.7671 - val_loss: 0.3021 - val_accuracy: 0.7338\n",
      "Epoch 380/1000\n",
      "614/614 [==============================] - 0s 235us/step - loss: 0.2911 - accuracy: 0.7720 - val_loss: 0.3027 - val_accuracy: 0.7403\n",
      "Epoch 381/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2909 - accuracy: 0.7720 - val_loss: 0.3008 - val_accuracy: 0.7273\n",
      "Epoch 382/1000\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.2901 - accuracy: 0.7606 - val_loss: 0.3065 - val_accuracy: 0.7338\n",
      "Epoch 383/1000\n",
      "614/614 [==============================] - 0s 234us/step - loss: 0.2900 - accuracy: 0.7801 - val_loss: 0.3003 - val_accuracy: 0.7403\n",
      "Epoch 384/1000\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.2913 - accuracy: 0.7622 - val_loss: 0.3215 - val_accuracy: 0.7078\n",
      "Epoch 385/1000\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.2944 - accuracy: 0.7785 - val_loss: 0.3003 - val_accuracy: 0.7338\n",
      "Epoch 386/1000\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.2911 - accuracy: 0.7752 - val_loss: 0.3105 - val_accuracy: 0.7403\n",
      "Epoch 387/1000\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.2919 - accuracy: 0.7622 - val_loss: 0.3089 - val_accuracy: 0.7338\n",
      "Epoch 388/1000\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.2908 - accuracy: 0.7687 - val_loss: 0.3032 - val_accuracy: 0.7403\n",
      "Epoch 389/1000\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.2895 - accuracy: 0.7801 - val_loss: 0.3018 - val_accuracy: 0.7468\n",
      "Epoch 390/1000\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.2889 - accuracy: 0.7785 - val_loss: 0.3043 - val_accuracy: 0.7532\n",
      "Epoch 391/1000\n",
      "614/614 [==============================] - 0s 235us/step - loss: 0.2886 - accuracy: 0.7736 - val_loss: 0.3017 - val_accuracy: 0.7338\n",
      "Epoch 392/1000\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.2921 - accuracy: 0.7606 - val_loss: 0.3187 - val_accuracy: 0.7078\n",
      "Epoch 393/1000\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.2908 - accuracy: 0.7785 - val_loss: 0.2996 - val_accuracy: 0.7273\n",
      "Epoch 394/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2902 - accuracy: 0.7801 - val_loss: 0.3019 - val_accuracy: 0.7338\n",
      "Epoch 395/1000\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.2883 - accuracy: 0.7720 - val_loss: 0.3222 - val_accuracy: 0.6818\n",
      "Epoch 396/1000\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.2974 - accuracy: 0.7785 - val_loss: 0.2997 - val_accuracy: 0.7338\n",
      "Epoch 397/1000\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.2931 - accuracy: 0.7606 - val_loss: 0.3127 - val_accuracy: 0.7403\n",
      "Epoch 398/1000\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.2890 - accuracy: 0.7834 - val_loss: 0.2995 - val_accuracy: 0.7273\n",
      "Epoch 399/1000\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.2910 - accuracy: 0.7638 - val_loss: 0.3131 - val_accuracy: 0.7273\n",
      "Epoch 400/1000\n",
      "614/614 [==============================] - 0s 235us/step - loss: 0.2904 - accuracy: 0.7638 - val_loss: 0.3049 - val_accuracy: 0.7468\n",
      "Epoch 401/1000\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.2882 - accuracy: 0.7769 - val_loss: 0.3035 - val_accuracy: 0.7597\n",
      "Epoch 402/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2890 - accuracy: 0.7671 - val_loss: 0.3083 - val_accuracy: 0.7338\n",
      "Epoch 403/1000\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.2882 - accuracy: 0.7818 - val_loss: 0.3000 - val_accuracy: 0.7403\n",
      "Epoch 404/1000\n",
      "614/614 [==============================] - 0s 235us/step - loss: 0.2873 - accuracy: 0.7736 - val_loss: 0.3065 - val_accuracy: 0.7338\n",
      "Epoch 405/1000\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.2878 - accuracy: 0.7752 - val_loss: 0.3006 - val_accuracy: 0.7403\n",
      "Epoch 406/1000\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.2867 - accuracy: 0.7785 - val_loss: 0.3002 - val_accuracy: 0.7403\n",
      "Epoch 407/1000\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.2863 - accuracy: 0.7720 - val_loss: 0.3094 - val_accuracy: 0.7338\n",
      "Epoch 408/1000\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.2867 - accuracy: 0.7948 - val_loss: 0.2977 - val_accuracy: 0.7468\n",
      "Epoch 409/1000\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.2891 - accuracy: 0.7785 - val_loss: 0.3057 - val_accuracy: 0.7468\n",
      "Epoch 410/1000\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.2883 - accuracy: 0.7769 - val_loss: 0.3079 - val_accuracy: 0.7403\n",
      "Epoch 411/1000\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.2855 - accuracy: 0.7769 - val_loss: 0.2980 - val_accuracy: 0.7208\n",
      "Epoch 412/1000\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.2898 - accuracy: 0.7801 - val_loss: 0.2991 - val_accuracy: 0.7468\n",
      "Epoch 413/1000\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.2870 - accuracy: 0.7704 - val_loss: 0.3073 - val_accuracy: 0.7338\n",
      "Epoch 414/1000\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.2857 - accuracy: 0.7818 - val_loss: 0.2969 - val_accuracy: 0.7273\n",
      "Epoch 415/1000\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.2860 - accuracy: 0.7801 - val_loss: 0.3083 - val_accuracy: 0.7403\n",
      "Epoch 416/1000\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.2856 - accuracy: 0.7720 - val_loss: 0.3035 - val_accuracy: 0.7468\n",
      "Epoch 417/1000\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.2860 - accuracy: 0.7785 - val_loss: 0.2973 - val_accuracy: 0.7273\n",
      "Epoch 418/1000\n",
      "614/614 [==============================] - 0s 235us/step - loss: 0.2847 - accuracy: 0.7769 - val_loss: 0.3013 - val_accuracy: 0.7532\n",
      "Epoch 419/1000\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.2842 - accuracy: 0.7671 - val_loss: 0.3022 - val_accuracy: 0.7597\n",
      "Epoch 420/1000\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.2843 - accuracy: 0.7671 - val_loss: 0.3022 - val_accuracy: 0.7532\n",
      "Epoch 421/1000\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.2843 - accuracy: 0.7801 - val_loss: 0.3035 - val_accuracy: 0.7468\n",
      "Epoch 422/1000\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.2827 - accuracy: 0.7801 - val_loss: 0.2980 - val_accuracy: 0.7468\n",
      "Epoch 423/1000\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.2859 - accuracy: 0.7850 - val_loss: 0.3006 - val_accuracy: 0.7403\n",
      "Epoch 424/1000\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.2846 - accuracy: 0.7785 - val_loss: 0.3144 - val_accuracy: 0.7208\n",
      "Epoch 425/1000\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.2887 - accuracy: 0.7850 - val_loss: 0.2963 - val_accuracy: 0.7662\n",
      "Epoch 426/1000\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.2874 - accuracy: 0.7687 - val_loss: 0.3046 - val_accuracy: 0.7532\n",
      "Epoch 427/1000\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.2847 - accuracy: 0.7687 - val_loss: 0.3068 - val_accuracy: 0.7468\n",
      "Epoch 428/1000\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.2870 - accuracy: 0.7769 - val_loss: 0.2969 - val_accuracy: 0.7662\n",
      "Epoch 429/1000\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.2856 - accuracy: 0.7801 - val_loss: 0.3017 - val_accuracy: 0.7597\n",
      "Epoch 430/1000\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.2829 - accuracy: 0.7834 - val_loss: 0.3013 - val_accuracy: 0.7597\n",
      "Epoch 431/1000\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.2824 - accuracy: 0.7785 - val_loss: 0.2977 - val_accuracy: 0.7403\n",
      "Epoch 432/1000\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.2829 - accuracy: 0.7736 - val_loss: 0.3024 - val_accuracy: 0.7468\n",
      "Epoch 433/1000\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.2825 - accuracy: 0.7752 - val_loss: 0.3006 - val_accuracy: 0.7532\n",
      "Epoch 434/1000\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.2834 - accuracy: 0.7850 - val_loss: 0.2963 - val_accuracy: 0.7662\n",
      "Epoch 435/1000\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.2844 - accuracy: 0.7622 - val_loss: 0.3059 - val_accuracy: 0.7468\n",
      "Epoch 436/1000\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.2830 - accuracy: 0.7736 - val_loss: 0.3014 - val_accuracy: 0.7532\n",
      "Epoch 437/1000\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.2820 - accuracy: 0.7964 - val_loss: 0.2998 - val_accuracy: 0.7468\n",
      "Epoch 438/1000\n",
      "614/614 [==============================] - 0s 251us/step - loss: 0.2827 - accuracy: 0.7720 - val_loss: 0.3034 - val_accuracy: 0.7532\n",
      "Epoch 439/1000\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.2816 - accuracy: 0.7785 - val_loss: 0.3019 - val_accuracy: 0.7532\n",
      "Epoch 440/1000\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.2814 - accuracy: 0.7769 - val_loss: 0.3011 - val_accuracy: 0.7597\n",
      "Epoch 441/1000\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.2810 - accuracy: 0.7720 - val_loss: 0.2987 - val_accuracy: 0.7403\n",
      "Epoch 442/1000\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.2824 - accuracy: 0.7720 - val_loss: 0.3030 - val_accuracy: 0.7532\n",
      "Epoch 443/1000\n",
      "614/614 [==============================] - 0s 232us/step - loss: 0.2807 - accuracy: 0.7834 - val_loss: 0.2988 - val_accuracy: 0.7532\n",
      "Epoch 444/1000\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.2815 - accuracy: 0.7785 - val_loss: 0.3110 - val_accuracy: 0.7403\n",
      "Epoch 445/1000\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.2822 - accuracy: 0.7932 - val_loss: 0.2949 - val_accuracy: 0.7727\n",
      "Epoch 446/1000\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.2834 - accuracy: 0.7850 - val_loss: 0.2964 - val_accuracy: 0.7468\n",
      "Epoch 447/1000\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.2828 - accuracy: 0.7834 - val_loss: 0.3195 - val_accuracy: 0.7143\n",
      "Epoch 448/1000\n",
      "614/614 [==============================] - 0s 232us/step - loss: 0.2851 - accuracy: 0.7720 - val_loss: 0.2951 - val_accuracy: 0.7403\n",
      "Epoch 449/1000\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.2835 - accuracy: 0.7834 - val_loss: 0.3113 - val_accuracy: 0.7403\n",
      "Epoch 450/1000\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.2820 - accuracy: 0.7850 - val_loss: 0.3025 - val_accuracy: 0.7532\n",
      "Epoch 451/1000\n",
      "614/614 [==============================] - 0s 234us/step - loss: 0.2804 - accuracy: 0.7769 - val_loss: 0.3001 - val_accuracy: 0.7597\n",
      "Epoch 452/1000\n",
      "614/614 [==============================] - 0s 235us/step - loss: 0.2798 - accuracy: 0.7769 - val_loss: 0.3075 - val_accuracy: 0.7468\n",
      "Epoch 453/1000\n",
      "614/614 [==============================] - 0s 235us/step - loss: 0.2816 - accuracy: 0.7736 - val_loss: 0.2956 - val_accuracy: 0.7532\n",
      "Epoch 454/1000\n",
      "614/614 [==============================] - 0s 234us/step - loss: 0.2815 - accuracy: 0.7866 - val_loss: 0.3029 - val_accuracy: 0.7532\n",
      "Epoch 455/1000\n",
      "614/614 [==============================] - 0s 269us/step - loss: 0.2817 - accuracy: 0.7785 - val_loss: 0.3061 - val_accuracy: 0.7403\n",
      "Epoch 456/1000\n",
      "614/614 [==============================] - 0s 325us/step - loss: 0.2814 - accuracy: 0.7801 - val_loss: 0.3056 - val_accuracy: 0.7597\n",
      "Epoch 457/1000\n",
      "614/614 [==============================] - 0s 319us/step - loss: 0.2810 - accuracy: 0.7704 - val_loss: 0.3000 - val_accuracy: 0.7468\n",
      "Epoch 458/1000\n",
      "614/614 [==============================] - 0s 424us/step - loss: 0.2788 - accuracy: 0.7801 - val_loss: 0.3048 - val_accuracy: 0.7532\n",
      "Epoch 459/1000\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.2808 - accuracy: 0.7850 - val_loss: 0.2977 - val_accuracy: 0.7468\n",
      "Epoch 460/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2795 - accuracy: 0.7915 - val_loss: 0.2965 - val_accuracy: 0.7403\n",
      "Epoch 461/1000\n",
      "614/614 [==============================] - 0s 269us/step - loss: 0.2793 - accuracy: 0.7850 - val_loss: 0.3010 - val_accuracy: 0.7597\n",
      "Epoch 462/1000\n",
      "614/614 [==============================] - 0s 255us/step - loss: 0.2789 - accuracy: 0.7834 - val_loss: 0.2989 - val_accuracy: 0.7468\n",
      "Epoch 463/1000\n",
      "614/614 [==============================] - 0s 256us/step - loss: 0.2788 - accuracy: 0.7866 - val_loss: 0.2956 - val_accuracy: 0.7403\n",
      "Epoch 464/1000\n",
      "614/614 [==============================] - 0s 279us/step - loss: 0.2784 - accuracy: 0.7883 - val_loss: 0.3018 - val_accuracy: 0.7597\n",
      "Epoch 465/1000\n",
      "614/614 [==============================] - 0s 251us/step - loss: 0.2811 - accuracy: 0.7785 - val_loss: 0.3152 - val_accuracy: 0.7338\n",
      "Epoch 466/1000\n",
      "614/614 [==============================] - 0s 260us/step - loss: 0.2835 - accuracy: 0.7655 - val_loss: 0.2994 - val_accuracy: 0.7403\n",
      "Epoch 467/1000\n",
      "614/614 [==============================] - 0s 378us/step - loss: 0.2789 - accuracy: 0.7932 - val_loss: 0.2988 - val_accuracy: 0.7532\n",
      "Epoch 468/1000\n",
      "614/614 [==============================] - 0s 316us/step - loss: 0.2786 - accuracy: 0.7752 - val_loss: 0.3022 - val_accuracy: 0.7597\n",
      "Epoch 469/1000\n",
      "614/614 [==============================] - 0s 378us/step - loss: 0.2787 - accuracy: 0.7948 - val_loss: 0.2946 - val_accuracy: 0.7403\n",
      "Epoch 470/1000\n",
      "614/614 [==============================] - 0s 355us/step - loss: 0.2779 - accuracy: 0.7866 - val_loss: 0.3137 - val_accuracy: 0.7273\n",
      "Epoch 471/1000\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.78 - 0s 306us/step - loss: 0.2832 - accuracy: 0.7785 - val_loss: 0.2980 - val_accuracy: 0.7532\n",
      "Epoch 472/1000\n",
      "614/614 [==============================] - 0s 330us/step - loss: 0.2808 - accuracy: 0.7899 - val_loss: 0.2954 - val_accuracy: 0.7403\n",
      "Epoch 473/1000\n",
      "614/614 [==============================] - 0s 339us/step - loss: 0.2862 - accuracy: 0.7573 - val_loss: 0.3196 - val_accuracy: 0.7078\n",
      "Epoch 474/1000\n",
      "614/614 [==============================] - 0s 305us/step - loss: 0.2807 - accuracy: 0.7866 - val_loss: 0.2940 - val_accuracy: 0.7662\n",
      "Epoch 475/1000\n",
      "614/614 [==============================] - 0s 292us/step - loss: 0.2801 - accuracy: 0.7948 - val_loss: 0.3011 - val_accuracy: 0.7532\n",
      "Epoch 476/1000\n",
      "614/614 [==============================] - 0s 279us/step - loss: 0.2784 - accuracy: 0.7769 - val_loss: 0.3062 - val_accuracy: 0.7597\n",
      "Epoch 477/1000\n",
      "614/614 [==============================] - 0s 308us/step - loss: 0.2826 - accuracy: 0.7736 - val_loss: 0.3016 - val_accuracy: 0.7468\n",
      "Epoch 478/1000\n",
      "614/614 [==============================] - 0s 314us/step - loss: 0.2835 - accuracy: 0.7899 - val_loss: 0.2949 - val_accuracy: 0.7403\n",
      "Epoch 479/1000\n",
      "614/614 [==============================] - 0s 311us/step - loss: 0.2790 - accuracy: 0.7866 - val_loss: 0.3004 - val_accuracy: 0.7532\n",
      "Epoch 480/1000\n",
      "614/614 [==============================] - 0s 323us/step - loss: 0.2784 - accuracy: 0.7736 - val_loss: 0.3050 - val_accuracy: 0.7532\n",
      "Epoch 481/1000\n",
      "614/614 [==============================] - 0s 282us/step - loss: 0.2797 - accuracy: 0.7752 - val_loss: 0.3017 - val_accuracy: 0.7662\n",
      "Epoch 482/1000\n",
      "614/614 [==============================] - 0s 348us/step - loss: 0.2767 - accuracy: 0.7883 - val_loss: 0.2977 - val_accuracy: 0.7532\n",
      "Epoch 483/1000\n",
      "614/614 [==============================] - 0s 433us/step - loss: 0.2775 - accuracy: 0.7850 - val_loss: 0.3085 - val_accuracy: 0.7468\n",
      "Epoch 484/1000\n",
      "614/614 [==============================] - 0s 389us/step - loss: 0.2768 - accuracy: 0.7850 - val_loss: 0.2950 - val_accuracy: 0.7338\n",
      "Epoch 485/1000\n",
      "614/614 [==============================] - 0s 348us/step - loss: 0.2762 - accuracy: 0.7899 - val_loss: 0.3034 - val_accuracy: 0.7597\n",
      "Epoch 486/1000\n",
      "614/614 [==============================] - 0s 370us/step - loss: 0.2768 - accuracy: 0.7964 - val_loss: 0.2941 - val_accuracy: 0.7532\n",
      "Epoch 487/1000\n",
      "614/614 [==============================] - 0s 411us/step - loss: 0.2766 - accuracy: 0.7834 - val_loss: 0.3070 - val_accuracy: 0.7403\n",
      "Epoch 488/1000\n",
      "614/614 [==============================] - 0s 247us/step - loss: 0.2796 - accuracy: 0.7964 - val_loss: 0.2956 - val_accuracy: 0.7597\n",
      "Epoch 489/1000\n",
      "614/614 [==============================] - 0s 315us/step - loss: 0.2775 - accuracy: 0.7899 - val_loss: 0.2972 - val_accuracy: 0.7532\n",
      "Epoch 490/1000\n",
      "614/614 [==============================] - 0s 418us/step - loss: 0.2763 - accuracy: 0.7932 - val_loss: 0.2929 - val_accuracy: 0.7338\n",
      "Epoch 491/1000\n",
      "614/614 [==============================] - 0s 269us/step - loss: 0.2769 - accuracy: 0.7850 - val_loss: 0.2997 - val_accuracy: 0.7532\n",
      "Epoch 492/1000\n",
      "614/614 [==============================] - 0s 266us/step - loss: 0.2754 - accuracy: 0.7818 - val_loss: 0.2993 - val_accuracy: 0.7597\n",
      "Epoch 493/1000\n",
      "614/614 [==============================] - 0s 282us/step - loss: 0.2756 - accuracy: 0.7866 - val_loss: 0.2964 - val_accuracy: 0.7403\n",
      "Epoch 494/1000\n",
      "614/614 [==============================] - 0s 294us/step - loss: 0.2757 - accuracy: 0.7818 - val_loss: 0.3124 - val_accuracy: 0.7338\n",
      "Epoch 495/1000\n",
      "614/614 [==============================] - 0s 320us/step - loss: 0.2798 - accuracy: 0.7818 - val_loss: 0.2955 - val_accuracy: 0.7532\n",
      "Epoch 496/1000\n",
      "614/614 [==============================] - 0s 266us/step - loss: 0.2773 - accuracy: 0.7964 - val_loss: 0.2940 - val_accuracy: 0.7727\n",
      "Epoch 497/1000\n",
      "614/614 [==============================] - 0s 395us/step - loss: 0.2775 - accuracy: 0.7785 - val_loss: 0.3109 - val_accuracy: 0.7403\n",
      "Epoch 498/1000\n",
      "614/614 [==============================] - 0s 373us/step - loss: 0.2747 - accuracy: 0.8029 - val_loss: 0.2920 - val_accuracy: 0.7727\n",
      "Epoch 499/1000\n",
      "614/614 [==============================] - 0s 374us/step - loss: 0.2770 - accuracy: 0.7834 - val_loss: 0.3033 - val_accuracy: 0.7532\n",
      "Epoch 500/1000\n",
      "614/614 [==============================] - 0s 410us/step - loss: 0.2773 - accuracy: 0.7752 - val_loss: 0.3090 - val_accuracy: 0.7338\n",
      "Epoch 501/1000\n",
      "614/614 [==============================] - 0s 256us/step - loss: 0.2785 - accuracy: 0.7866 - val_loss: 0.2926 - val_accuracy: 0.7597\n",
      "Epoch 502/1000\n",
      "614/614 [==============================] - 0s 398us/step - loss: 0.2776 - accuracy: 0.7834 - val_loss: 0.3017 - val_accuracy: 0.7532\n",
      "Epoch 503/1000\n",
      "614/614 [==============================] - 0s 283us/step - loss: 0.2743 - accuracy: 0.7834 - val_loss: 0.2985 - val_accuracy: 0.7532\n",
      "Epoch 504/1000\n",
      "614/614 [==============================] - 0s 234us/step - loss: 0.2744 - accuracy: 0.7948 - val_loss: 0.2931 - val_accuracy: 0.7662\n",
      "Epoch 505/1000\n",
      "614/614 [==============================] - 0s 287us/step - loss: 0.2744 - accuracy: 0.7915 - val_loss: 0.3009 - val_accuracy: 0.7532\n",
      "Epoch 506/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.2742 - accuracy: 0.7948 - val_loss: 0.2961 - val_accuracy: 0.7597\n",
      "Epoch 507/1000\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.2745 - accuracy: 0.7932 - val_loss: 0.3011 - val_accuracy: 0.7468\n",
      "Epoch 508/1000\n",
      "614/614 [==============================] - 0s 258us/step - loss: 0.2744 - accuracy: 0.8078 - val_loss: 0.2919 - val_accuracy: 0.7597\n",
      "Epoch 509/1000\n",
      "614/614 [==============================] - 0s 256us/step - loss: 0.2756 - accuracy: 0.7850 - val_loss: 0.3143 - val_accuracy: 0.7338\n",
      "Epoch 510/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2785 - accuracy: 0.7752 - val_loss: 0.2916 - val_accuracy: 0.7662\n",
      "Epoch 511/1000\n",
      "614/614 [==============================] - 0s 279us/step - loss: 0.2730 - accuracy: 0.7915 - val_loss: 0.3060 - val_accuracy: 0.7532\n",
      "Epoch 512/1000\n",
      "614/614 [==============================] - 0s 263us/step - loss: 0.2744 - accuracy: 0.7915 - val_loss: 0.2935 - val_accuracy: 0.7662\n",
      "Epoch 513/1000\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.2727 - accuracy: 0.7915 - val_loss: 0.2972 - val_accuracy: 0.7597\n",
      "Epoch 514/1000\n",
      "614/614 [==============================] - 0s 257us/step - loss: 0.2739 - accuracy: 0.7932 - val_loss: 0.2903 - val_accuracy: 0.7597\n",
      "Epoch 515/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2758 - accuracy: 0.7850 - val_loss: 0.3035 - val_accuracy: 0.7532\n",
      "Epoch 516/1000\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.2724 - accuracy: 0.7997 - val_loss: 0.2911 - val_accuracy: 0.7597\n",
      "Epoch 517/1000\n",
      "614/614 [==============================] - 0s 278us/step - loss: 0.2739 - accuracy: 0.7948 - val_loss: 0.2957 - val_accuracy: 0.7597\n",
      "Epoch 518/1000\n",
      "614/614 [==============================] - 0s 352us/step - loss: 0.2718 - accuracy: 0.7883 - val_loss: 0.2992 - val_accuracy: 0.7597\n",
      "Epoch 519/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2726 - accuracy: 0.7834 - val_loss: 0.2978 - val_accuracy: 0.7597\n",
      "Epoch 520/1000\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.2724 - accuracy: 0.7883 - val_loss: 0.2965 - val_accuracy: 0.7532\n",
      "Epoch 521/1000\n",
      "614/614 [==============================] - 0s 280us/step - loss: 0.2715 - accuracy: 0.7883 - val_loss: 0.2939 - val_accuracy: 0.7662\n",
      "Epoch 522/1000\n",
      "614/614 [==============================] - 0s 271us/step - loss: 0.2721 - accuracy: 0.7948 - val_loss: 0.3038 - val_accuracy: 0.7532\n",
      "Epoch 523/1000\n",
      "614/614 [==============================] - 0s 269us/step - loss: 0.2746 - accuracy: 0.8078 - val_loss: 0.2888 - val_accuracy: 0.7922\n",
      "Epoch 524/1000\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.2732 - accuracy: 0.7964 - val_loss: 0.2958 - val_accuracy: 0.7727\n",
      "Epoch 525/1000\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.2740 - accuracy: 0.7834 - val_loss: 0.3026 - val_accuracy: 0.7597\n",
      "Epoch 526/1000\n",
      "614/614 [==============================] - 0s 258us/step - loss: 0.2758 - accuracy: 0.7915 - val_loss: 0.2888 - val_accuracy: 0.7597\n",
      "Epoch 527/1000\n",
      "614/614 [==============================] - 0s 277us/step - loss: 0.2769 - accuracy: 0.7704 - val_loss: 0.3144 - val_accuracy: 0.7273\n",
      "Epoch 528/1000\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.2744 - accuracy: 0.7915 - val_loss: 0.2888 - val_accuracy: 0.7727\n",
      "Epoch 529/1000\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.2761 - accuracy: 0.7818 - val_loss: 0.2929 - val_accuracy: 0.7597\n",
      "Epoch 530/1000\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.2748 - accuracy: 0.7883 - val_loss: 0.3117 - val_accuracy: 0.7338\n",
      "Epoch 531/1000\n",
      "614/614 [==============================] - 0s 234us/step - loss: 0.2826 - accuracy: 0.7736 - val_loss: 0.2876 - val_accuracy: 0.7792\n",
      "Epoch 532/1000\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.2746 - accuracy: 0.7736 - val_loss: 0.2975 - val_accuracy: 0.7662\n",
      "Epoch 533/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2720 - accuracy: 0.7883 - val_loss: 0.2978 - val_accuracy: 0.7532\n",
      "Epoch 534/1000\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.2717 - accuracy: 0.8046 - val_loss: 0.2886 - val_accuracy: 0.7597\n",
      "Epoch 535/1000\n",
      "614/614 [==============================] - 0s 260us/step - loss: 0.2719 - accuracy: 0.7948 - val_loss: 0.3103 - val_accuracy: 0.7468\n",
      "Epoch 536/1000\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.2746 - accuracy: 0.7818 - val_loss: 0.2886 - val_accuracy: 0.7792\n",
      "Epoch 537/1000\n",
      "614/614 [==============================] - 0s 260us/step - loss: 0.2720 - accuracy: 0.7915 - val_loss: 0.3018 - val_accuracy: 0.7597\n",
      "Epoch 538/1000\n",
      "614/614 [==============================] - 0s 248us/step - loss: 0.2734 - accuracy: 0.7834 - val_loss: 0.2983 - val_accuracy: 0.7727\n",
      "Epoch 539/1000\n",
      "614/614 [==============================] - 0s 257us/step - loss: 0.2701 - accuracy: 0.7948 - val_loss: 0.2906 - val_accuracy: 0.7727\n",
      "Epoch 540/1000\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.2732 - accuracy: 0.7883 - val_loss: 0.3046 - val_accuracy: 0.7532\n",
      "Epoch 541/1000\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.2739 - accuracy: 0.7769 - val_loss: 0.2967 - val_accuracy: 0.7532\n",
      "Epoch 542/1000\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.2733 - accuracy: 0.7932 - val_loss: 0.2899 - val_accuracy: 0.7857\n",
      "Epoch 543/1000\n",
      "614/614 [==============================] - 0s 264us/step - loss: 0.2697 - accuracy: 0.7899 - val_loss: 0.3036 - val_accuracy: 0.7597\n",
      "Epoch 544/1000\n",
      "614/614 [==============================] - 0s 298us/step - loss: 0.2706 - accuracy: 0.7980 - val_loss: 0.2898 - val_accuracy: 0.7857\n",
      "Epoch 545/1000\n",
      "614/614 [==============================] - 0s 266us/step - loss: 0.2708 - accuracy: 0.7883 - val_loss: 0.2959 - val_accuracy: 0.7727\n",
      "Epoch 546/1000\n",
      "614/614 [==============================] - 0s 280us/step - loss: 0.2698 - accuracy: 0.7980 - val_loss: 0.2981 - val_accuracy: 0.7597\n",
      "Epoch 547/1000\n",
      "614/614 [==============================] - 0s 278us/step - loss: 0.2696 - accuracy: 0.8013 - val_loss: 0.2889 - val_accuracy: 0.7792\n",
      "Epoch 548/1000\n",
      "614/614 [==============================] - 0s 277us/step - loss: 0.2719 - accuracy: 0.7980 - val_loss: 0.3072 - val_accuracy: 0.7403\n",
      "Epoch 549/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2716 - accuracy: 0.7883 - val_loss: 0.2927 - val_accuracy: 0.7727\n",
      "Epoch 550/1000\n",
      "614/614 [==============================] - 0s 257us/step - loss: 0.2715 - accuracy: 0.7850 - val_loss: 0.2962 - val_accuracy: 0.7597\n",
      "Epoch 551/1000\n",
      "614/614 [==============================] - 0s 248us/step - loss: 0.2703 - accuracy: 0.7866 - val_loss: 0.2948 - val_accuracy: 0.7727\n",
      "Epoch 552/1000\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.2700 - accuracy: 0.7915 - val_loss: 0.2934 - val_accuracy: 0.7727\n",
      "Epoch 553/1000\n",
      "614/614 [==============================] - 0s 256us/step - loss: 0.2691 - accuracy: 0.7932 - val_loss: 0.2896 - val_accuracy: 0.7662\n",
      "Epoch 554/1000\n",
      "614/614 [==============================] - 0s 269us/step - loss: 0.2695 - accuracy: 0.7980 - val_loss: 0.2932 - val_accuracy: 0.7727\n",
      "Epoch 555/1000\n",
      "614/614 [==============================] - 0s 289us/step - loss: 0.2695 - accuracy: 0.8111 - val_loss: 0.2867 - val_accuracy: 0.7727\n",
      "Epoch 556/1000\n",
      "614/614 [==============================] - 0s 262us/step - loss: 0.2727 - accuracy: 0.7915 - val_loss: 0.3004 - val_accuracy: 0.7662\n",
      "Epoch 557/1000\n",
      "614/614 [==============================] - 0s 273us/step - loss: 0.2706 - accuracy: 0.7980 - val_loss: 0.2969 - val_accuracy: 0.7662\n",
      "Epoch 558/1000\n",
      "614/614 [==============================] - 0s 262us/step - loss: 0.2765 - accuracy: 0.7769 - val_loss: 0.2852 - val_accuracy: 0.7597\n",
      "Epoch 559/1000\n",
      "614/614 [==============================] - 0s 272us/step - loss: 0.2778 - accuracy: 0.7752 - val_loss: 0.3207 - val_accuracy: 0.7078\n",
      "Epoch 560/1000\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.2729 - accuracy: 0.7997 - val_loss: 0.2862 - val_accuracy: 0.7662\n",
      "Epoch 561/1000\n",
      "614/614 [==============================] - 0s 281us/step - loss: 0.2709 - accuracy: 0.7915 - val_loss: 0.2967 - val_accuracy: 0.7857\n",
      "Epoch 562/1000\n",
      "614/614 [==============================] - 0s 288us/step - loss: 0.2691 - accuracy: 0.7866 - val_loss: 0.3011 - val_accuracy: 0.7792\n",
      "Epoch 563/1000\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.2690 - accuracy: 0.7899 - val_loss: 0.2896 - val_accuracy: 0.7727\n",
      "Epoch 564/1000\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.2709 - accuracy: 0.8013 - val_loss: 0.3040 - val_accuracy: 0.7662\n",
      "Epoch 565/1000\n",
      "614/614 [==============================] - 0s 314us/step - loss: 0.2689 - accuracy: 0.7899 - val_loss: 0.2922 - val_accuracy: 0.7662\n",
      "Epoch 566/1000\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.2683 - accuracy: 0.7964 - val_loss: 0.2895 - val_accuracy: 0.7727\n",
      "Epoch 567/1000\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.2674 - accuracy: 0.7932 - val_loss: 0.2936 - val_accuracy: 0.7727\n",
      "Epoch 568/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2676 - accuracy: 0.7980 - val_loss: 0.2939 - val_accuracy: 0.7662\n",
      "Epoch 569/1000\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.2672 - accuracy: 0.7997 - val_loss: 0.2899 - val_accuracy: 0.7727\n",
      "Epoch 570/1000\n",
      "614/614 [==============================] - 0s 257us/step - loss: 0.2668 - accuracy: 0.7866 - val_loss: 0.2961 - val_accuracy: 0.7727\n",
      "Epoch 571/1000\n",
      "614/614 [==============================] - 0s 261us/step - loss: 0.2680 - accuracy: 0.7980 - val_loss: 0.2924 - val_accuracy: 0.7727\n",
      "Epoch 572/1000\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.2668 - accuracy: 0.8046 - val_loss: 0.2922 - val_accuracy: 0.7857\n",
      "Epoch 573/1000\n",
      "614/614 [==============================] - 0s 253us/step - loss: 0.2685 - accuracy: 0.7866 - val_loss: 0.2993 - val_accuracy: 0.7662\n",
      "Epoch 574/1000\n",
      "614/614 [==============================] - 0s 251us/step - loss: 0.2673 - accuracy: 0.8013 - val_loss: 0.2915 - val_accuracy: 0.7597\n",
      "Epoch 575/1000\n",
      "614/614 [==============================] - 0s 273us/step - loss: 0.2658 - accuracy: 0.7964 - val_loss: 0.2934 - val_accuracy: 0.7727\n",
      "Epoch 576/1000\n",
      "614/614 [==============================] - 0s 234us/step - loss: 0.2686 - accuracy: 0.7883 - val_loss: 0.2975 - val_accuracy: 0.7662\n",
      "Epoch 577/1000\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.2653 - accuracy: 0.8062 - val_loss: 0.2867 - val_accuracy: 0.7922\n",
      "Epoch 578/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2655 - accuracy: 0.8013 - val_loss: 0.2968 - val_accuracy: 0.7597\n",
      "Epoch 579/1000\n",
      "614/614 [==============================] - 0s 256us/step - loss: 0.2659 - accuracy: 0.7997 - val_loss: 0.2868 - val_accuracy: 0.7792\n",
      "Epoch 580/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2668 - accuracy: 0.7899 - val_loss: 0.3031 - val_accuracy: 0.7662\n",
      "Epoch 581/1000\n",
      "614/614 [==============================] - 0s 247us/step - loss: 0.2686 - accuracy: 0.7932 - val_loss: 0.2957 - val_accuracy: 0.7727\n",
      "Epoch 582/1000\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.2686 - accuracy: 0.7932 - val_loss: 0.2888 - val_accuracy: 0.7727\n",
      "Epoch 583/1000\n",
      "614/614 [==============================] - 0s 257us/step - loss: 0.2681 - accuracy: 0.7850 - val_loss: 0.2875 - val_accuracy: 0.7662\n",
      "Epoch 584/1000\n",
      "614/614 [==============================] - 0s 247us/step - loss: 0.2677 - accuracy: 0.8013 - val_loss: 0.2979 - val_accuracy: 0.7662\n",
      "Epoch 585/1000\n",
      "614/614 [==============================] - 0s 236us/step - loss: 0.2666 - accuracy: 0.7932 - val_loss: 0.2922 - val_accuracy: 0.7662\n",
      "Epoch 586/1000\n",
      "614/614 [==============================] - 0s 271us/step - loss: 0.2658 - accuracy: 0.7964 - val_loss: 0.2933 - val_accuracy: 0.7727\n",
      "Epoch 587/1000\n",
      "614/614 [==============================] - 0s 303us/step - loss: 0.2653 - accuracy: 0.7964 - val_loss: 0.2908 - val_accuracy: 0.7727\n",
      "Epoch 588/1000\n",
      "614/614 [==============================] - 0s 256us/step - loss: 0.2658 - accuracy: 0.7997 - val_loss: 0.2850 - val_accuracy: 0.7857\n",
      "Epoch 589/1000\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.2659 - accuracy: 0.7948 - val_loss: 0.2974 - val_accuracy: 0.7662\n",
      "Epoch 590/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2659 - accuracy: 0.7980 - val_loss: 0.2879 - val_accuracy: 0.7727\n",
      "Epoch 591/1000\n",
      "614/614 [==============================] - 0s 248us/step - loss: 0.2652 - accuracy: 0.7980 - val_loss: 0.2882 - val_accuracy: 0.7792\n",
      "Epoch 592/1000\n",
      "614/614 [==============================] - 0s 270us/step - loss: 0.2664 - accuracy: 0.8046 - val_loss: 0.2845 - val_accuracy: 0.7792\n",
      "Epoch 593/1000\n",
      "614/614 [==============================] - 0s 247us/step - loss: 0.2658 - accuracy: 0.7932 - val_loss: 0.3055 - val_accuracy: 0.7532\n",
      "Epoch 594/1000\n",
      "614/614 [==============================] - 0s 267us/step - loss: 0.2673 - accuracy: 0.7964 - val_loss: 0.2906 - val_accuracy: 0.7792\n",
      "Epoch 595/1000\n",
      "614/614 [==============================] - 0s 278us/step - loss: 0.2666 - accuracy: 0.7997 - val_loss: 0.2851 - val_accuracy: 0.7792\n",
      "Epoch 596/1000\n",
      "614/614 [==============================] - 0s 251us/step - loss: 0.2658 - accuracy: 0.7997 - val_loss: 0.2888 - val_accuracy: 0.7727\n",
      "Epoch 597/1000\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.2637 - accuracy: 0.8046 - val_loss: 0.2891 - val_accuracy: 0.7727\n",
      "Epoch 598/1000\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.2641 - accuracy: 0.8078 - val_loss: 0.2895 - val_accuracy: 0.7792\n",
      "Epoch 599/1000\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.2645 - accuracy: 0.7997 - val_loss: 0.2896 - val_accuracy: 0.7792\n",
      "Epoch 600/1000\n",
      "614/614 [==============================] - 0s 236us/step - loss: 0.2644 - accuracy: 0.7948 - val_loss: 0.2842 - val_accuracy: 0.7922\n",
      "Epoch 601/1000\n",
      "614/614 [==============================] - 0s 263us/step - loss: 0.2666 - accuracy: 0.8029 - val_loss: 0.2990 - val_accuracy: 0.7468\n",
      "Epoch 602/1000\n",
      "614/614 [==============================] - 0s 294us/step - loss: 0.2659 - accuracy: 0.7997 - val_loss: 0.2878 - val_accuracy: 0.7792\n",
      "Epoch 603/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2635 - accuracy: 0.8127 - val_loss: 0.2886 - val_accuracy: 0.7727\n",
      "Epoch 604/1000\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.2634 - accuracy: 0.8013 - val_loss: 0.2936 - val_accuracy: 0.7727\n",
      "Epoch 605/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2686 - accuracy: 0.7915 - val_loss: 0.2839 - val_accuracy: 0.7662\n",
      "Epoch 606/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.2658 - accuracy: 0.7964 - val_loss: 0.2890 - val_accuracy: 0.7727\n",
      "Epoch 607/1000\n",
      "614/614 [==============================] - 0s 251us/step - loss: 0.2660 - accuracy: 0.7948 - val_loss: 0.3098 - val_accuracy: 0.7403\n",
      "Epoch 608/1000\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.2679 - accuracy: 0.7948 - val_loss: 0.2825 - val_accuracy: 0.7727\n",
      "Epoch 609/1000\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.2644 - accuracy: 0.8062 - val_loss: 0.2933 - val_accuracy: 0.7662\n",
      "Epoch 610/1000\n",
      "614/614 [==============================] - 0s 290us/step - loss: 0.2668 - accuracy: 0.7964 - val_loss: 0.3023 - val_accuracy: 0.7532\n",
      "Epoch 611/1000\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.2628 - accuracy: 0.7980 - val_loss: 0.2846 - val_accuracy: 0.7857\n",
      "Epoch 612/1000\n",
      "614/614 [==============================] - 0s 261us/step - loss: 0.2643 - accuracy: 0.7997 - val_loss: 0.2931 - val_accuracy: 0.7597\n",
      "Epoch 613/1000\n",
      "614/614 [==============================] - 0s 280us/step - loss: 0.2641 - accuracy: 0.7964 - val_loss: 0.2872 - val_accuracy: 0.7792\n",
      "Epoch 614/1000\n",
      "614/614 [==============================] - 0s 235us/step - loss: 0.2628 - accuracy: 0.7997 - val_loss: 0.2903 - val_accuracy: 0.7792\n",
      "Epoch 615/1000\n",
      "614/614 [==============================] - 0s 271us/step - loss: 0.2643 - accuracy: 0.7980 - val_loss: 0.2839 - val_accuracy: 0.7922\n",
      "Epoch 616/1000\n",
      "614/614 [==============================] - 0s 300us/step - loss: 0.2630 - accuracy: 0.8094 - val_loss: 0.2941 - val_accuracy: 0.7727\n",
      "Epoch 617/1000\n",
      "614/614 [==============================] - 0s 297us/step - loss: 0.2626 - accuracy: 0.8013 - val_loss: 0.2898 - val_accuracy: 0.7662\n",
      "Epoch 618/1000\n",
      "614/614 [==============================] - 0s 270us/step - loss: 0.2629 - accuracy: 0.8094 - val_loss: 0.2918 - val_accuracy: 0.7727\n",
      "Epoch 619/1000\n",
      "614/614 [==============================] - 0s 273us/step - loss: 0.2626 - accuracy: 0.8078 - val_loss: 0.2921 - val_accuracy: 0.7792\n",
      "Epoch 620/1000\n",
      "614/614 [==============================] - 0s 278us/step - loss: 0.2657 - accuracy: 0.7997 - val_loss: 0.2864 - val_accuracy: 0.7727\n",
      "Epoch 621/1000\n",
      "614/614 [==============================] - 0s 306us/step - loss: 0.2620 - accuracy: 0.8013 - val_loss: 0.2925 - val_accuracy: 0.7857\n",
      "Epoch 622/1000\n",
      "614/614 [==============================] - 0s 315us/step - loss: 0.2627 - accuracy: 0.7997 - val_loss: 0.2925 - val_accuracy: 0.7792\n",
      "Epoch 623/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2625 - accuracy: 0.8094 - val_loss: 0.2849 - val_accuracy: 0.7792\n",
      "Epoch 624/1000\n",
      "614/614 [==============================] - 0s 330us/step - loss: 0.2656 - accuracy: 0.7785 - val_loss: 0.3088 - val_accuracy: 0.7532\n",
      "Epoch 625/1000\n",
      "614/614 [==============================] - 0s 278us/step - loss: 0.2641 - accuracy: 0.7997 - val_loss: 0.2852 - val_accuracy: 0.7922\n",
      "Epoch 626/1000\n",
      "614/614 [==============================] - 0s 261us/step - loss: 0.2624 - accuracy: 0.8160 - val_loss: 0.3108 - val_accuracy: 0.7273\n",
      "Epoch 627/1000\n",
      "614/614 [==============================] - 0s 253us/step - loss: 0.2703 - accuracy: 0.7915 - val_loss: 0.2816 - val_accuracy: 0.7792\n",
      "Epoch 628/1000\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.2668 - accuracy: 0.8094 - val_loss: 0.2879 - val_accuracy: 0.7727\n",
      "Epoch 629/1000\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.2626 - accuracy: 0.7997 - val_loss: 0.2899 - val_accuracy: 0.7792\n",
      "Epoch 630/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2631 - accuracy: 0.8013 - val_loss: 0.2978 - val_accuracy: 0.7532\n",
      "Epoch 631/1000\n",
      "614/614 [==============================] - 0s 265us/step - loss: 0.2633 - accuracy: 0.8062 - val_loss: 0.2846 - val_accuracy: 0.7987\n",
      "Epoch 632/1000\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.2673 - accuracy: 0.7866 - val_loss: 0.3016 - val_accuracy: 0.7532\n",
      "Epoch 633/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2648 - accuracy: 0.8029 - val_loss: 0.2844 - val_accuracy: 0.7792\n",
      "Epoch 634/1000\n",
      "614/614 [==============================] - 0s 232us/step - loss: 0.2665 - accuracy: 0.7997 - val_loss: 0.2821 - val_accuracy: 0.7857\n",
      "Epoch 635/1000\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.2683 - accuracy: 0.7850 - val_loss: 0.3034 - val_accuracy: 0.7597\n",
      "Epoch 636/1000\n",
      "614/614 [==============================] - 0s 236us/step - loss: 0.2617 - accuracy: 0.8143 - val_loss: 0.2841 - val_accuracy: 0.7922\n",
      "Epoch 637/1000\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.2645 - accuracy: 0.8029 - val_loss: 0.2888 - val_accuracy: 0.7792\n",
      "Epoch 638/1000\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.2645 - accuracy: 0.7948 - val_loss: 0.3014 - val_accuracy: 0.7597\n",
      "Epoch 639/1000\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.2642 - accuracy: 0.8029 - val_loss: 0.2823 - val_accuracy: 0.7857\n",
      "Epoch 640/1000\n",
      "614/614 [==============================] - 0s 298us/step - loss: 0.2632 - accuracy: 0.7997 - val_loss: 0.2983 - val_accuracy: 0.7597\n",
      "Epoch 641/1000\n",
      "614/614 [==============================] - 0s 314us/step - loss: 0.2647 - accuracy: 0.8029 - val_loss: 0.2931 - val_accuracy: 0.7727\n",
      "Epoch 642/1000\n",
      "614/614 [==============================] - 0s 323us/step - loss: 0.2667 - accuracy: 0.7883 - val_loss: 0.2879 - val_accuracy: 0.7792\n",
      "Epoch 643/1000\n",
      "614/614 [==============================] - 0s 335us/step - loss: 0.2635 - accuracy: 0.8062 - val_loss: 0.2843 - val_accuracy: 0.7922\n",
      "Epoch 644/1000\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.2618 - accuracy: 0.8029 - val_loss: 0.2965 - val_accuracy: 0.7662\n",
      "Epoch 645/1000\n",
      "614/614 [==============================] - 0s 280us/step - loss: 0.2636 - accuracy: 0.7964 - val_loss: 0.2832 - val_accuracy: 0.7792\n",
      "Epoch 646/1000\n",
      "614/614 [==============================] - 0s 299us/step - loss: 0.2626 - accuracy: 0.7915 - val_loss: 0.2856 - val_accuracy: 0.7792\n",
      "Epoch 647/1000\n",
      "614/614 [==============================] - 0s 295us/step - loss: 0.2607 - accuracy: 0.8127 - val_loss: 0.2876 - val_accuracy: 0.7727\n",
      "Epoch 648/1000\n",
      "614/614 [==============================] - 0s 248us/step - loss: 0.2612 - accuracy: 0.8094 - val_loss: 0.2866 - val_accuracy: 0.7792\n",
      "Epoch 649/1000\n",
      "614/614 [==============================] - 0s 308us/step - loss: 0.2609 - accuracy: 0.8127 - val_loss: 0.2941 - val_accuracy: 0.7727\n",
      "Epoch 650/1000\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.2607 - accuracy: 0.8208 - val_loss: 0.2857 - val_accuracy: 0.7857\n",
      "Epoch 651/1000\n",
      "614/614 [==============================] - 0s 298us/step - loss: 0.2618 - accuracy: 0.8062 - val_loss: 0.2952 - val_accuracy: 0.7792\n",
      "Epoch 652/1000\n",
      "614/614 [==============================] - 0s 284us/step - loss: 0.2613 - accuracy: 0.7997 - val_loss: 0.2915 - val_accuracy: 0.7727\n",
      "Epoch 653/1000\n",
      "614/614 [==============================] - 0s 258us/step - loss: 0.2618 - accuracy: 0.8013 - val_loss: 0.2951 - val_accuracy: 0.7727\n",
      "Epoch 654/1000\n",
      "614/614 [==============================] - 0s 258us/step - loss: 0.2614 - accuracy: 0.8078 - val_loss: 0.2851 - val_accuracy: 0.7792\n",
      "Epoch 655/1000\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.2616 - accuracy: 0.7948 - val_loss: 0.2913 - val_accuracy: 0.7727\n",
      "Epoch 656/1000\n",
      "614/614 [==============================] - 0s 243us/step - loss: 0.2600 - accuracy: 0.8111 - val_loss: 0.2858 - val_accuracy: 0.7792\n",
      "Epoch 657/1000\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.2608 - accuracy: 0.8046 - val_loss: 0.2812 - val_accuracy: 0.7792\n",
      "Epoch 658/1000\n",
      "614/614 [==============================] - 0s 274us/step - loss: 0.2624 - accuracy: 0.8029 - val_loss: 0.2931 - val_accuracy: 0.7662\n",
      "Epoch 659/1000\n",
      "614/614 [==============================] - 0s 275us/step - loss: 0.2611 - accuracy: 0.8160 - val_loss: 0.2888 - val_accuracy: 0.7727\n",
      "Epoch 660/1000\n",
      "614/614 [==============================] - 0s 322us/step - loss: 0.2600 - accuracy: 0.8046 - val_loss: 0.2873 - val_accuracy: 0.7792\n",
      "Epoch 661/1000\n",
      "614/614 [==============================] - 0s 402us/step - loss: 0.2620 - accuracy: 0.8111 - val_loss: 0.2816 - val_accuracy: 0.7922\n",
      "Epoch 662/1000\n",
      "614/614 [==============================] - 0s 420us/step - loss: 0.2618 - accuracy: 0.7932 - val_loss: 0.2981 - val_accuracy: 0.7597\n",
      "Epoch 663/1000\n",
      "614/614 [==============================] - 0s 292us/step - loss: 0.2630 - accuracy: 0.8013 - val_loss: 0.2901 - val_accuracy: 0.7857\n",
      "Epoch 664/1000\n",
      "614/614 [==============================] - 0s 291us/step - loss: 0.2616 - accuracy: 0.8046 - val_loss: 0.2995 - val_accuracy: 0.7662\n",
      "Epoch 665/1000\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.2684 - accuracy: 0.7939 ETA: 0s - loss: 0.2743 - accuracy: 0. - 0s 313us/step - loss: 0.2652 - accuracy: 0.7915 - val_loss: 0.2805 - val_accuracy: 0.7727\n",
      "Epoch 666/1000\n",
      "614/614 [==============================] - 0s 301us/step - loss: 0.2650 - accuracy: 0.8029 - val_loss: 0.3008 - val_accuracy: 0.7468\n",
      "Epoch 667/1000\n",
      "614/614 [==============================] - 0s 341us/step - loss: 0.2617 - accuracy: 0.7964 - val_loss: 0.2889 - val_accuracy: 0.7727\n",
      "Epoch 668/1000\n",
      "614/614 [==============================] - 0s 334us/step - loss: 0.2628 - accuracy: 0.8094 - val_loss: 0.2814 - val_accuracy: 0.8052\n",
      "Epoch 669/1000\n",
      "614/614 [==============================] - 0s 471us/step - loss: 0.2625 - accuracy: 0.7883 - val_loss: 0.2858 - val_accuracy: 0.7727\n",
      "Epoch 670/1000\n",
      "614/614 [==============================] - 0s 338us/step - loss: 0.2595 - accuracy: 0.8094 - val_loss: 0.2987 - val_accuracy: 0.7727\n",
      "Epoch 671/1000\n",
      "614/614 [==============================] - 0s 309us/step - loss: 0.2622 - accuracy: 0.8078 - val_loss: 0.2818 - val_accuracy: 0.7922\n",
      "Epoch 672/1000\n",
      "614/614 [==============================] - 0s 341us/step - loss: 0.2652 - accuracy: 0.7932 - val_loss: 0.2894 - val_accuracy: 0.7792\n",
      "Epoch 673/1000\n",
      "614/614 [==============================] - 0s 343us/step - loss: 0.2619 - accuracy: 0.7899 - val_loss: 0.3006 - val_accuracy: 0.7468\n",
      "Epoch 674/1000\n",
      "614/614 [==============================] - 0s 332us/step - loss: 0.2636 - accuracy: 0.8143 - val_loss: 0.2816 - val_accuracy: 0.7857\n",
      "Epoch 675/1000\n",
      "614/614 [==============================] - 0s 346us/step - loss: 0.2639 - accuracy: 0.7997 - val_loss: 0.2859 - val_accuracy: 0.7792\n",
      "Epoch 676/1000\n",
      "614/614 [==============================] - 0s 340us/step - loss: 0.2609 - accuracy: 0.7948 - val_loss: 0.2984 - val_accuracy: 0.7662\n",
      "Epoch 677/1000\n",
      "614/614 [==============================] - 0s 494us/step - loss: 0.2630 - accuracy: 0.8078 - val_loss: 0.2846 - val_accuracy: 0.7857\n",
      "Epoch 678/1000\n",
      "614/614 [==============================] - 0s 342us/step - loss: 0.2590 - accuracy: 0.8078 - val_loss: 0.2916 - val_accuracy: 0.7792\n",
      "Epoch 679/1000\n",
      "614/614 [==============================] - 0s 403us/step - loss: 0.2605 - accuracy: 0.7997 - val_loss: 0.2908 - val_accuracy: 0.7727\n",
      "Epoch 680/1000\n",
      "614/614 [==============================] - 0s 315us/step - loss: 0.2595 - accuracy: 0.8111 - val_loss: 0.2859 - val_accuracy: 0.7857\n",
      "Epoch 681/1000\n",
      "614/614 [==============================] - 0s 352us/step - loss: 0.2612 - accuracy: 0.8029 - val_loss: 0.3039 - val_accuracy: 0.7532\n",
      "Epoch 682/1000\n",
      "614/614 [==============================] - 0s 329us/step - loss: 0.2638 - accuracy: 0.8094 - val_loss: 0.2813 - val_accuracy: 0.7922\n",
      "Epoch 683/1000\n",
      "614/614 [==============================] - 0s 304us/step - loss: 0.2640 - accuracy: 0.7997 - val_loss: 0.2884 - val_accuracy: 0.7662\n",
      "Epoch 684/1000\n",
      "614/614 [==============================] - 0s 332us/step - loss: 0.2606 - accuracy: 0.7948 - val_loss: 0.2973 - val_accuracy: 0.7597\n",
      "Epoch 685/1000\n",
      "614/614 [==============================] - 0s 337us/step - loss: 0.2609 - accuracy: 0.8094 - val_loss: 0.2812 - val_accuracy: 0.7727\n",
      "Epoch 686/1000\n",
      "614/614 [==============================] - 0s 322us/step - loss: 0.2604 - accuracy: 0.8046 - val_loss: 0.2959 - val_accuracy: 0.7532\n",
      "Epoch 687/1000\n",
      "614/614 [==============================] - 0s 324us/step - loss: 0.2594 - accuracy: 0.7980 - val_loss: 0.2848 - val_accuracy: 0.7792\n",
      "Epoch 688/1000\n",
      "614/614 [==============================] - 0s 328us/step - loss: 0.2610 - accuracy: 0.8111 - val_loss: 0.2819 - val_accuracy: 0.7987\n",
      "Epoch 689/1000\n",
      "614/614 [==============================] - 0s 276us/step - loss: 0.2623 - accuracy: 0.8046 - val_loss: 0.2968 - val_accuracy: 0.7597\n",
      "Epoch 690/1000\n",
      "614/614 [==============================] - 0s 316us/step - loss: 0.2595 - accuracy: 0.8062 - val_loss: 0.2832 - val_accuracy: 0.7857\n",
      "Epoch 691/1000\n",
      "614/614 [==============================] - 0s 301us/step - loss: 0.2627 - accuracy: 0.8029 - val_loss: 0.2812 - val_accuracy: 0.7922\n",
      "Epoch 692/1000\n",
      "614/614 [==============================] - 0s 311us/step - loss: 0.2696 - accuracy: 0.7866 - val_loss: 0.3240 - val_accuracy: 0.6818\n",
      "Epoch 693/1000\n",
      "614/614 [==============================] - 0s 369us/step - loss: 0.2710 - accuracy: 0.7850 - val_loss: 0.2842 - val_accuracy: 0.7857\n",
      "Epoch 694/1000\n",
      "614/614 [==============================] - 0s 379us/step - loss: 0.2588 - accuracy: 0.8078 - val_loss: 0.2892 - val_accuracy: 0.7662\n",
      "Epoch 695/1000\n",
      "614/614 [==============================] - 0s 306us/step - loss: 0.2621 - accuracy: 0.8046 - val_loss: 0.2827 - val_accuracy: 0.7792\n",
      "Epoch 696/1000\n",
      "614/614 [==============================] - 0s 354us/step - loss: 0.2647 - accuracy: 0.7980 - val_loss: 0.2966 - val_accuracy: 0.7597\n",
      "Epoch 697/1000\n",
      "614/614 [==============================] - 0s 326us/step - loss: 0.2634 - accuracy: 0.7899 - val_loss: 0.2983 - val_accuracy: 0.7597\n",
      "Epoch 698/1000\n",
      "614/614 [==============================] - 0s 342us/step - loss: 0.2619 - accuracy: 0.8046 - val_loss: 0.2814 - val_accuracy: 0.7727\n",
      "Epoch 699/1000\n",
      "614/614 [==============================] - 0s 350us/step - loss: 0.2601 - accuracy: 0.8029 - val_loss: 0.2878 - val_accuracy: 0.7792\n",
      "Epoch 700/1000\n",
      "614/614 [==============================] - 0s 288us/step - loss: 0.2594 - accuracy: 0.8046 - val_loss: 0.2983 - val_accuracy: 0.7532\n",
      "Epoch 701/1000\n",
      "614/614 [==============================] - 0s 345us/step - loss: 0.2605 - accuracy: 0.8078 - val_loss: 0.2826 - val_accuracy: 0.7922\n",
      "Epoch 702/1000\n",
      "614/614 [==============================] - 0s 300us/step - loss: 0.2610 - accuracy: 0.8062 - val_loss: 0.2929 - val_accuracy: 0.7792\n",
      "Epoch 703/1000\n",
      "614/614 [==============================] - 0s 292us/step - loss: 0.2594 - accuracy: 0.8078 - val_loss: 0.2867 - val_accuracy: 0.7727\n",
      "Epoch 704/1000\n",
      "614/614 [==============================] - 0s 323us/step - loss: 0.2587 - accuracy: 0.8078 - val_loss: 0.2832 - val_accuracy: 0.7792\n",
      "Epoch 705/1000\n",
      "614/614 [==============================] - 0s 348us/step - loss: 0.2597 - accuracy: 0.8013 - val_loss: 0.2858 - val_accuracy: 0.7792\n",
      "Epoch 706/1000\n",
      "614/614 [==============================] - 0s 327us/step - loss: 0.2589 - accuracy: 0.8094 - val_loss: 0.2840 - val_accuracy: 0.7922\n",
      "Epoch 707/1000\n",
      "614/614 [==============================] - 0s 296us/step - loss: 0.2604 - accuracy: 0.7915 - val_loss: 0.2957 - val_accuracy: 0.7662\n",
      "Epoch 708/1000\n",
      "614/614 [==============================] - 0s 320us/step - loss: 0.2599 - accuracy: 0.7948 - val_loss: 0.2906 - val_accuracy: 0.7727\n",
      "Epoch 709/1000\n",
      "614/614 [==============================] - 0s 333us/step - loss: 0.2600 - accuracy: 0.8013 - val_loss: 0.2915 - val_accuracy: 0.7662\n",
      "Epoch 710/1000\n",
      "614/614 [==============================] - 0s 370us/step - loss: 0.2630 - accuracy: 0.8062 - val_loss: 0.2796 - val_accuracy: 0.7727\n",
      "Epoch 711/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.2608 - accuracy: 0.7964 - val_loss: 0.3036 - val_accuracy: 0.7468\n",
      "Epoch 712/1000\n",
      "614/614 [==============================] - 0s 291us/step - loss: 0.2598 - accuracy: 0.8078 - val_loss: 0.2821 - val_accuracy: 0.7857\n",
      "Epoch 713/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.2605 - accuracy: 0.8078 - val_loss: 0.2855 - val_accuracy: 0.7727\n",
      "Epoch 714/1000\n",
      "614/614 [==============================] - 0s 319us/step - loss: 0.2600 - accuracy: 0.8013 - val_loss: 0.3010 - val_accuracy: 0.7468\n",
      "Epoch 715/1000\n",
      "614/614 [==============================] - 0s 280us/step - loss: 0.2612 - accuracy: 0.7997 - val_loss: 0.2854 - val_accuracy: 0.7792\n",
      "Epoch 716/1000\n",
      "614/614 [==============================] - 0s 328us/step - loss: 0.2572 - accuracy: 0.8192 - val_loss: 0.2892 - val_accuracy: 0.7727\n",
      "Epoch 717/1000\n",
      "614/614 [==============================] - 0s 380us/step - loss: 0.2584 - accuracy: 0.8062 - val_loss: 0.2853 - val_accuracy: 0.7857\n",
      "Epoch 718/1000\n",
      "614/614 [==============================] - 0s 374us/step - loss: 0.2582 - accuracy: 0.8111 - val_loss: 0.2980 - val_accuracy: 0.7597\n",
      "Epoch 719/1000\n",
      "614/614 [==============================] - 0s 332us/step - loss: 0.2574 - accuracy: 0.7997 - val_loss: 0.2807 - val_accuracy: 0.7792\n",
      "Epoch 720/1000\n",
      "614/614 [==============================] - 0s 306us/step - loss: 0.2619 - accuracy: 0.8013 - val_loss: 0.2967 - val_accuracy: 0.7662\n",
      "Epoch 721/1000\n",
      "614/614 [==============================] - 0s 322us/step - loss: 0.2594 - accuracy: 0.8143 - val_loss: 0.2851 - val_accuracy: 0.7857\n",
      "Epoch 722/1000\n",
      "614/614 [==============================] - 0s 290us/step - loss: 0.2637 - accuracy: 0.8127 - val_loss: 0.2829 - val_accuracy: 0.7792\n",
      "Epoch 723/1000\n",
      "614/614 [==============================] - 0s 304us/step - loss: 0.2608 - accuracy: 0.8029 - val_loss: 0.3052 - val_accuracy: 0.7403\n",
      "Epoch 724/1000\n",
      "614/614 [==============================] - 0s 320us/step - loss: 0.2599 - accuracy: 0.7980 - val_loss: 0.2832 - val_accuracy: 0.7792\n",
      "Epoch 725/1000\n",
      "614/614 [==============================] - 0s 340us/step - loss: 0.2603 - accuracy: 0.8192 - val_loss: 0.2841 - val_accuracy: 0.7857\n",
      "Epoch 726/1000\n",
      "614/614 [==============================] - 0s 328us/step - loss: 0.2579 - accuracy: 0.8111 - val_loss: 0.2981 - val_accuracy: 0.7597\n",
      "Epoch 727/1000\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.2490 - accuracy: 0.82 - 0s 311us/step - loss: 0.2592 - accuracy: 0.8062 - val_loss: 0.2835 - val_accuracy: 0.7792\n",
      "Epoch 728/1000\n",
      "614/614 [==============================] - 0s 324us/step - loss: 0.2568 - accuracy: 0.8176 - val_loss: 0.2967 - val_accuracy: 0.7727\n",
      "Epoch 729/1000\n",
      "614/614 [==============================] - 0s 289us/step - loss: 0.2581 - accuracy: 0.8208 - val_loss: 0.2811 - val_accuracy: 0.7922\n",
      "Epoch 730/1000\n",
      "614/614 [==============================] - 0s 325us/step - loss: 0.2587 - accuracy: 0.8094 - val_loss: 0.2872 - val_accuracy: 0.7792\n",
      "Epoch 731/1000\n",
      "614/614 [==============================] - 0s 302us/step - loss: 0.2583 - accuracy: 0.7980 - val_loss: 0.2922 - val_accuracy: 0.7727\n",
      "Epoch 732/1000\n",
      "614/614 [==============================] - 0s 311us/step - loss: 0.2577 - accuracy: 0.8127 - val_loss: 0.2873 - val_accuracy: 0.7792\n",
      "Epoch 733/1000\n",
      "614/614 [==============================] - 0s 288us/step - loss: 0.2576 - accuracy: 0.8078 - val_loss: 0.2853 - val_accuracy: 0.7792\n",
      "Epoch 734/1000\n",
      "614/614 [==============================] - 0s 296us/step - loss: 0.2566 - accuracy: 0.8062 - val_loss: 0.2898 - val_accuracy: 0.7662\n",
      "Epoch 735/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.2577 - accuracy: 0.8078 - val_loss: 0.2878 - val_accuracy: 0.7727\n",
      "Epoch 736/1000\n",
      "614/614 [==============================] - 0s 296us/step - loss: 0.2576 - accuracy: 0.8111 - val_loss: 0.2956 - val_accuracy: 0.7662\n",
      "Epoch 737/1000\n",
      "614/614 [==============================] - 0s 314us/step - loss: 0.2573 - accuracy: 0.8062 - val_loss: 0.2834 - val_accuracy: 0.7857\n",
      "Epoch 738/1000\n",
      "614/614 [==============================] - 0s 327us/step - loss: 0.2569 - accuracy: 0.8078 - val_loss: 0.2851 - val_accuracy: 0.7792\n",
      "Epoch 739/1000\n",
      "614/614 [==============================] - 0s 318us/step - loss: 0.2575 - accuracy: 0.8046 - val_loss: 0.2935 - val_accuracy: 0.7727\n",
      "Epoch 740/1000\n",
      "614/614 [==============================] - 0s 324us/step - loss: 0.2560 - accuracy: 0.8176 - val_loss: 0.2840 - val_accuracy: 0.7792\n",
      "Epoch 741/1000\n",
      "614/614 [==============================] - 0s 301us/step - loss: 0.2568 - accuracy: 0.8176 - val_loss: 0.2878 - val_accuracy: 0.7727\n",
      "Epoch 742/1000\n",
      "614/614 [==============================] - 0s 281us/step - loss: 0.2563 - accuracy: 0.8078 - val_loss: 0.2866 - val_accuracy: 0.7857\n",
      "Epoch 743/1000\n",
      "614/614 [==============================] - 0s 274us/step - loss: 0.2580 - accuracy: 0.7948 - val_loss: 0.2816 - val_accuracy: 0.7857\n",
      "Epoch 744/1000\n",
      "614/614 [==============================] - 0s 333us/step - loss: 0.2577 - accuracy: 0.8192 - val_loss: 0.2858 - val_accuracy: 0.7727\n",
      "Epoch 745/1000\n",
      "614/614 [==============================] - 0s 387us/step - loss: 0.2572 - accuracy: 0.8094 - val_loss: 0.2821 - val_accuracy: 0.7792\n",
      "Epoch 746/1000\n",
      "614/614 [==============================] - 0s 325us/step - loss: 0.2591 - accuracy: 0.7964 - val_loss: 0.3053 - val_accuracy: 0.7403\n",
      "Epoch 747/1000\n",
      "614/614 [==============================] - 0s 317us/step - loss: 0.2593 - accuracy: 0.7980 - val_loss: 0.2824 - val_accuracy: 0.7857\n",
      "Epoch 748/1000\n",
      "614/614 [==============================] - 0s 308us/step - loss: 0.2579 - accuracy: 0.8111 - val_loss: 0.2821 - val_accuracy: 0.7922\n",
      "Epoch 749/1000\n",
      "614/614 [==============================] - 0s 315us/step - loss: 0.2575 - accuracy: 0.8094 - val_loss: 0.3017 - val_accuracy: 0.7532\n",
      "Epoch 750/1000\n",
      "614/614 [==============================] - 0s 354us/step - loss: 0.2582 - accuracy: 0.7964 - val_loss: 0.2802 - val_accuracy: 0.7792\n",
      "Epoch 751/1000\n",
      "614/614 [==============================] - 0s 332us/step - loss: 0.2607 - accuracy: 0.7980 - val_loss: 0.2923 - val_accuracy: 0.7727\n",
      "Epoch 752/1000\n",
      "614/614 [==============================] - 0s 355us/step - loss: 0.2576 - accuracy: 0.8046 - val_loss: 0.2915 - val_accuracy: 0.7792\n",
      "Epoch 753/1000\n",
      "614/614 [==============================] - 0s 314us/step - loss: 0.2633 - accuracy: 0.7948 - val_loss: 0.2801 - val_accuracy: 0.7857\n",
      "Epoch 754/1000\n",
      "614/614 [==============================] - 0s 324us/step - loss: 0.2632 - accuracy: 0.7980 - val_loss: 0.2870 - val_accuracy: 0.7922\n",
      "Epoch 755/1000\n",
      "614/614 [==============================] - 0s 332us/step - loss: 0.2577 - accuracy: 0.8029 - val_loss: 0.2929 - val_accuracy: 0.7662\n",
      "Epoch 756/1000\n",
      "614/614 [==============================] - 0s 306us/step - loss: 0.2585 - accuracy: 0.8094 - val_loss: 0.2799 - val_accuracy: 0.7727\n",
      "Epoch 757/1000\n",
      "614/614 [==============================] - 0s 333us/step - loss: 0.2581 - accuracy: 0.7997 - val_loss: 0.3000 - val_accuracy: 0.7597\n",
      "Epoch 758/1000\n",
      "614/614 [==============================] - 0s 303us/step - loss: 0.2572 - accuracy: 0.8078 - val_loss: 0.2809 - val_accuracy: 0.7857\n",
      "Epoch 759/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.2567 - accuracy: 0.8143 - val_loss: 0.2866 - val_accuracy: 0.7857\n",
      "Epoch 760/1000\n",
      "614/614 [==============================] - 0s 288us/step - loss: 0.2555 - accuracy: 0.8143 - val_loss: 0.2835 - val_accuracy: 0.7857\n",
      "Epoch 761/1000\n",
      "614/614 [==============================] - 0s 282us/step - loss: 0.2574 - accuracy: 0.8013 - val_loss: 0.2960 - val_accuracy: 0.7597\n",
      "Epoch 762/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.2561 - accuracy: 0.8094 - val_loss: 0.2825 - val_accuracy: 0.7857\n",
      "Epoch 763/1000\n",
      "614/614 [==============================] - 0s 299us/step - loss: 0.2607 - accuracy: 0.7964 - val_loss: 0.2830 - val_accuracy: 0.7857\n",
      "Epoch 764/1000\n",
      "614/614 [==============================] - 0s 286us/step - loss: 0.2618 - accuracy: 0.7980 - val_loss: 0.2961 - val_accuracy: 0.7662\n",
      "Epoch 765/1000\n",
      "614/614 [==============================] - 0s 266us/step - loss: 0.2558 - accuracy: 0.8208 - val_loss: 0.2843 - val_accuracy: 0.7857\n",
      "Epoch 766/1000\n",
      "614/614 [==============================] - 0s 291us/step - loss: 0.2558 - accuracy: 0.8094 - val_loss: 0.2880 - val_accuracy: 0.7727\n",
      "Epoch 767/1000\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.2555 - accuracy: 0.8111 - val_loss: 0.2847 - val_accuracy: 0.7857\n",
      "Epoch 768/1000\n",
      "614/614 [==============================] - 0s 296us/step - loss: 0.2559 - accuracy: 0.8078 - val_loss: 0.2860 - val_accuracy: 0.7792\n",
      "Epoch 769/1000\n",
      "614/614 [==============================] - 0s 274us/step - loss: 0.2548 - accuracy: 0.8225 - val_loss: 0.2866 - val_accuracy: 0.7857\n",
      "Epoch 770/1000\n",
      "614/614 [==============================] - 0s 291us/step - loss: 0.2570 - accuracy: 0.8046 - val_loss: 0.2911 - val_accuracy: 0.7727\n",
      "Epoch 771/1000\n",
      "614/614 [==============================] - 0s 295us/step - loss: 0.2554 - accuracy: 0.8111 - val_loss: 0.2798 - val_accuracy: 0.7727\n",
      "Epoch 772/1000\n",
      "614/614 [==============================] - 0s 321us/step - loss: 0.2616 - accuracy: 0.7964 - val_loss: 0.2949 - val_accuracy: 0.7662\n",
      "Epoch 773/1000\n",
      "614/614 [==============================] - 0s 334us/step - loss: 0.2564 - accuracy: 0.8062 - val_loss: 0.2869 - val_accuracy: 0.7792\n",
      "Epoch 774/1000\n",
      "614/614 [==============================] - 0s 363us/step - loss: 0.2563 - accuracy: 0.8094 - val_loss: 0.2861 - val_accuracy: 0.7857\n",
      "Epoch 775/1000\n",
      "614/614 [==============================] - 0s 333us/step - loss: 0.2547 - accuracy: 0.8046 - val_loss: 0.2827 - val_accuracy: 0.7857\n",
      "Epoch 776/1000\n",
      "614/614 [==============================] - 0s 368us/step - loss: 0.2580 - accuracy: 0.8078 - val_loss: 0.2818 - val_accuracy: 0.7922\n",
      "Epoch 777/1000\n",
      "614/614 [==============================] - 0s 426us/step - loss: 0.2586 - accuracy: 0.8029 - val_loss: 0.2862 - val_accuracy: 0.7857\n",
      "Epoch 778/1000\n",
      "614/614 [==============================] - 0s 319us/step - loss: 0.2546 - accuracy: 0.8111 - val_loss: 0.2899 - val_accuracy: 0.7597\n",
      "Epoch 779/1000\n",
      "614/614 [==============================] - 0s 334us/step - loss: 0.2549 - accuracy: 0.8127 - val_loss: 0.2891 - val_accuracy: 0.7857\n",
      "Epoch 780/1000\n",
      "614/614 [==============================] - 0s 366us/step - loss: 0.2553 - accuracy: 0.8062 - val_loss: 0.2888 - val_accuracy: 0.7857\n",
      "Epoch 781/1000\n",
      "614/614 [==============================] - 0s 369us/step - loss: 0.2549 - accuracy: 0.8160 - val_loss: 0.2864 - val_accuracy: 0.7792\n",
      "Epoch 782/1000\n",
      "614/614 [==============================] - 0s 308us/step - loss: 0.2542 - accuracy: 0.8160 - val_loss: 0.2864 - val_accuracy: 0.7792\n",
      "Epoch 783/1000\n",
      "614/614 [==============================] - 0s 344us/step - loss: 0.2547 - accuracy: 0.8046 - val_loss: 0.2898 - val_accuracy: 0.7857\n",
      "Epoch 784/1000\n",
      "614/614 [==============================] - 0s 347us/step - loss: 0.2544 - accuracy: 0.8192 - val_loss: 0.2827 - val_accuracy: 0.7922\n",
      "Epoch 785/1000\n",
      "614/614 [==============================] - 0s 335us/step - loss: 0.2577 - accuracy: 0.8094 - val_loss: 0.2941 - val_accuracy: 0.7727\n",
      "Epoch 786/1000\n",
      "614/614 [==============================] - 0s 357us/step - loss: 0.2536 - accuracy: 0.8208 - val_loss: 0.2795 - val_accuracy: 0.7987\n",
      "Epoch 787/1000\n",
      "614/614 [==============================] - 0s 344us/step - loss: 0.2560 - accuracy: 0.8013 - val_loss: 0.2892 - val_accuracy: 0.7662\n",
      "Epoch 788/1000\n",
      "614/614 [==============================] - 0s 463us/step - loss: 0.2567 - accuracy: 0.8127 - val_loss: 0.2977 - val_accuracy: 0.7662\n",
      "Epoch 789/1000\n",
      "614/614 [==============================] - 0s 332us/step - loss: 0.2561 - accuracy: 0.8078 - val_loss: 0.2825 - val_accuracy: 0.7857\n",
      "Epoch 790/1000\n",
      "614/614 [==============================] - 0s 317us/step - loss: 0.2551 - accuracy: 0.8062 - val_loss: 0.2857 - val_accuracy: 0.7922\n",
      "Epoch 791/1000\n",
      "614/614 [==============================] - 0s 331us/step - loss: 0.2566 - accuracy: 0.8143 - val_loss: 0.2916 - val_accuracy: 0.7727\n",
      "Epoch 792/1000\n",
      "614/614 [==============================] - 0s 385us/step - loss: 0.2572 - accuracy: 0.8029 - val_loss: 0.2978 - val_accuracy: 0.7468\n",
      "Epoch 793/1000\n",
      "614/614 [==============================] - 0s 340us/step - loss: 0.2675 - accuracy: 0.7932 - val_loss: 0.2772 - val_accuracy: 0.7857\n",
      "Epoch 794/1000\n",
      "614/614 [==============================] - 0s 330us/step - loss: 0.2600 - accuracy: 0.8029 - val_loss: 0.2898 - val_accuracy: 0.7922\n",
      "Epoch 795/1000\n",
      "614/614 [==============================] - 0s 350us/step - loss: 0.2538 - accuracy: 0.8078 - val_loss: 0.2837 - val_accuracy: 0.7857\n",
      "Epoch 796/1000\n",
      "614/614 [==============================] - 0s 332us/step - loss: 0.2552 - accuracy: 0.8160 - val_loss: 0.2951 - val_accuracy: 0.7727\n",
      "Epoch 797/1000\n",
      "614/614 [==============================] - 0s 303us/step - loss: 0.2552 - accuracy: 0.8094 - val_loss: 0.2842 - val_accuracy: 0.7857\n",
      "Epoch 798/1000\n",
      "614/614 [==============================] - 0s 287us/step - loss: 0.2544 - accuracy: 0.8176 - val_loss: 0.2838 - val_accuracy: 0.7857\n",
      "Epoch 799/1000\n",
      "614/614 [==============================] - 0s 306us/step - loss: 0.2548 - accuracy: 0.8127 - val_loss: 0.2834 - val_accuracy: 0.7857\n",
      "Epoch 800/1000\n",
      "614/614 [==============================] - 0s 314us/step - loss: 0.2543 - accuracy: 0.8078 - val_loss: 0.2930 - val_accuracy: 0.7532\n",
      "Epoch 801/1000\n",
      "614/614 [==============================] - 0s 325us/step - loss: 0.2545 - accuracy: 0.8143 - val_loss: 0.2880 - val_accuracy: 0.7922\n",
      "Epoch 802/1000\n",
      "614/614 [==============================] - 0s 304us/step - loss: 0.2536 - accuracy: 0.8208 - val_loss: 0.2818 - val_accuracy: 0.7922\n",
      "Epoch 803/1000\n",
      "614/614 [==============================] - 0s 286us/step - loss: 0.2564 - accuracy: 0.8094 - val_loss: 0.3022 - val_accuracy: 0.7597\n",
      "Epoch 804/1000\n",
      "614/614 [==============================] - 0s 309us/step - loss: 0.2585 - accuracy: 0.8111 - val_loss: 0.2844 - val_accuracy: 0.7922\n",
      "Epoch 805/1000\n",
      "614/614 [==============================] - 0s 332us/step - loss: 0.2533 - accuracy: 0.8160 - val_loss: 0.2906 - val_accuracy: 0.7532\n",
      "Epoch 806/1000\n",
      "614/614 [==============================] - 0s 337us/step - loss: 0.2550 - accuracy: 0.8127 - val_loss: 0.2885 - val_accuracy: 0.7727\n",
      "Epoch 807/1000\n",
      "614/614 [==============================] - 0s 331us/step - loss: 0.2544 - accuracy: 0.8143 - val_loss: 0.2802 - val_accuracy: 0.7792\n",
      "Epoch 808/1000\n",
      "614/614 [==============================] - 0s 316us/step - loss: 0.2562 - accuracy: 0.8078 - val_loss: 0.2939 - val_accuracy: 0.7662\n",
      "Epoch 809/1000\n",
      "614/614 [==============================] - 0s 276us/step - loss: 0.2570 - accuracy: 0.8094 - val_loss: 0.2988 - val_accuracy: 0.7403\n",
      "Epoch 810/1000\n",
      "614/614 [==============================] - 0s 289us/step - loss: 0.2557 - accuracy: 0.8094 - val_loss: 0.2810 - val_accuracy: 0.8052\n",
      "Epoch 811/1000\n",
      "614/614 [==============================] - 0s 301us/step - loss: 0.2542 - accuracy: 0.8111 - val_loss: 0.2855 - val_accuracy: 0.7857\n",
      "Epoch 812/1000\n",
      "614/614 [==============================] - 0s 289us/step - loss: 0.2535 - accuracy: 0.8111 - val_loss: 0.2895 - val_accuracy: 0.7922\n",
      "Epoch 813/1000\n",
      "614/614 [==============================] - 0s 275us/step - loss: 0.2546 - accuracy: 0.8127 - val_loss: 0.2819 - val_accuracy: 0.7987\n",
      "Epoch 814/1000\n",
      "614/614 [==============================] - 0s 291us/step - loss: 0.2551 - accuracy: 0.8111 - val_loss: 0.2814 - val_accuracy: 0.7857\n",
      "Epoch 815/1000\n",
      "614/614 [==============================] - 0s 286us/step - loss: 0.2543 - accuracy: 0.8143 - val_loss: 0.2955 - val_accuracy: 0.7727\n",
      "Epoch 816/1000\n",
      "614/614 [==============================] - 0s 303us/step - loss: 0.2556 - accuracy: 0.8078 - val_loss: 0.2902 - val_accuracy: 0.7792\n",
      "Epoch 817/1000\n",
      "614/614 [==============================] - 0s 328us/step - loss: 0.2534 - accuracy: 0.8160 - val_loss: 0.2840 - val_accuracy: 0.7857\n",
      "Epoch 818/1000\n",
      "614/614 [==============================] - 0s 295us/step - loss: 0.2550 - accuracy: 0.8176 - val_loss: 0.2933 - val_accuracy: 0.7727\n",
      "Epoch 819/1000\n",
      "614/614 [==============================] - 0s 323us/step - loss: 0.2540 - accuracy: 0.8143 - val_loss: 0.2872 - val_accuracy: 0.7727\n",
      "Epoch 820/1000\n",
      "614/614 [==============================] - 0s 286us/step - loss: 0.2572 - accuracy: 0.8029 - val_loss: 0.2785 - val_accuracy: 0.8052\n",
      "Epoch 821/1000\n",
      "614/614 [==============================] - 0s 301us/step - loss: 0.2566 - accuracy: 0.8029 - val_loss: 0.2883 - val_accuracy: 0.7727\n",
      "Epoch 822/1000\n",
      "614/614 [==============================] - 0s 320us/step - loss: 0.2559 - accuracy: 0.8127 - val_loss: 0.2982 - val_accuracy: 0.7532\n",
      "Epoch 823/1000\n",
      "614/614 [==============================] - 0s 312us/step - loss: 0.2573 - accuracy: 0.8078 - val_loss: 0.2793 - val_accuracy: 0.8052\n",
      "Epoch 824/1000\n",
      "614/614 [==============================] - 0s 306us/step - loss: 0.2574 - accuracy: 0.8111 - val_loss: 0.2885 - val_accuracy: 0.7597\n",
      "Epoch 825/1000\n",
      "614/614 [==============================] - 0s 296us/step - loss: 0.2545 - accuracy: 0.8176 - val_loss: 0.2880 - val_accuracy: 0.7922\n",
      "Epoch 826/1000\n",
      "614/614 [==============================] - 0s 294us/step - loss: 0.2533 - accuracy: 0.8143 - val_loss: 0.2788 - val_accuracy: 0.7987\n",
      "Epoch 827/1000\n",
      "614/614 [==============================] - 0s 308us/step - loss: 0.2561 - accuracy: 0.8046 - val_loss: 0.2990 - val_accuracy: 0.7403\n",
      "Epoch 828/1000\n",
      "614/614 [==============================] - 0s 316us/step - loss: 0.2554 - accuracy: 0.8127 - val_loss: 0.2805 - val_accuracy: 0.7987\n",
      "Epoch 829/1000\n",
      "614/614 [==============================] - 0s 348us/step - loss: 0.2588 - accuracy: 0.8013 - val_loss: 0.2806 - val_accuracy: 0.7922\n",
      "Epoch 830/1000\n",
      "614/614 [==============================] - 0s 377us/step - loss: 0.2571 - accuracy: 0.8046 - val_loss: 0.3002 - val_accuracy: 0.7468\n",
      "Epoch 831/1000\n",
      "614/614 [==============================] - 0s 526us/step - loss: 0.2550 - accuracy: 0.8225 - val_loss: 0.2823 - val_accuracy: 0.7792\n",
      "Epoch 832/1000\n",
      "614/614 [==============================] - 0s 366us/step - loss: 0.2568 - accuracy: 0.8046 - val_loss: 0.2796 - val_accuracy: 0.7792\n",
      "Epoch 833/1000\n",
      "614/614 [==============================] - 0s 377us/step - loss: 0.2584 - accuracy: 0.8176 - val_loss: 0.2958 - val_accuracy: 0.7597\n",
      "Epoch 834/1000\n",
      "614/614 [==============================] - 0s 284us/step - loss: 0.2542 - accuracy: 0.8143 - val_loss: 0.2874 - val_accuracy: 0.7792\n",
      "Epoch 835/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2531 - accuracy: 0.8143 - val_loss: 0.2852 - val_accuracy: 0.7857\n",
      "Epoch 836/1000\n",
      "614/614 [==============================] - 0s 253us/step - loss: 0.2531 - accuracy: 0.8111 - val_loss: 0.2934 - val_accuracy: 0.7662\n",
      "Epoch 837/1000\n",
      "614/614 [==============================] - 0s 272us/step - loss: 0.2521 - accuracy: 0.8208 - val_loss: 0.2801 - val_accuracy: 0.7857\n",
      "Epoch 838/1000\n",
      "614/614 [==============================] - 0s 299us/step - loss: 0.2539 - accuracy: 0.8078 - val_loss: 0.2851 - val_accuracy: 0.7857\n",
      "Epoch 839/1000\n",
      "614/614 [==============================] - 0s 266us/step - loss: 0.2543 - accuracy: 0.8062 - val_loss: 0.2821 - val_accuracy: 0.7922\n",
      "Epoch 840/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2536 - accuracy: 0.8143 - val_loss: 0.2838 - val_accuracy: 0.7922\n",
      "Epoch 841/1000\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.2545 - accuracy: 0.8094 - val_loss: 0.2846 - val_accuracy: 0.7792\n",
      "Epoch 842/1000\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.2533 - accuracy: 0.8111 - val_loss: 0.2870 - val_accuracy: 0.7987\n",
      "Epoch 843/1000\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.2541 - accuracy: 0.8062 - val_loss: 0.3013 - val_accuracy: 0.7468\n",
      "Epoch 844/1000\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.2526 - accuracy: 0.8176 - val_loss: 0.2776 - val_accuracy: 0.7857\n",
      "Epoch 845/1000\n",
      "614/614 [==============================] - 0s 285us/step - loss: 0.2693 - accuracy: 0.7785 - val_loss: 0.2958 - val_accuracy: 0.7792\n",
      "Epoch 846/1000\n",
      "614/614 [==============================] - 0s 344us/step - loss: 0.2552 - accuracy: 0.7948 - val_loss: 0.2945 - val_accuracy: 0.7662\n",
      "Epoch 847/1000\n",
      "614/614 [==============================] - 0s 323us/step - loss: 0.2536 - accuracy: 0.8078 - val_loss: 0.2821 - val_accuracy: 0.7857\n",
      "Epoch 848/1000\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.2525 - accuracy: 0.8176 - val_loss: 0.2917 - val_accuracy: 0.7792\n",
      "Epoch 849/1000\n",
      "614/614 [==============================] - 0s 268us/step - loss: 0.2539 - accuracy: 0.8127 - val_loss: 0.2949 - val_accuracy: 0.7727\n",
      "Epoch 850/1000\n",
      "614/614 [==============================] - 0s 261us/step - loss: 0.2534 - accuracy: 0.8078 - val_loss: 0.2910 - val_accuracy: 0.7857\n",
      "Epoch 851/1000\n",
      "614/614 [==============================] - 0s 248us/step - loss: 0.2534 - accuracy: 0.8094 - val_loss: 0.2820 - val_accuracy: 0.7857\n",
      "Epoch 852/1000\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.2528 - accuracy: 0.8111 - val_loss: 0.2944 - val_accuracy: 0.7662\n",
      "Epoch 853/1000\n",
      "614/614 [==============================] - 0s 255us/step - loss: 0.2538 - accuracy: 0.8078 - val_loss: 0.2891 - val_accuracy: 0.7727\n",
      "Epoch 854/1000\n",
      "614/614 [==============================] - 0s 251us/step - loss: 0.2519 - accuracy: 0.8160 - val_loss: 0.2871 - val_accuracy: 0.7922\n",
      "Epoch 855/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2525 - accuracy: 0.8111 - val_loss: 0.2835 - val_accuracy: 0.7857\n",
      "Epoch 856/1000\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.2523 - accuracy: 0.8111 - val_loss: 0.2905 - val_accuracy: 0.7597\n",
      "Epoch 857/1000\n",
      "614/614 [==============================] - 0s 236us/step - loss: 0.2522 - accuracy: 0.8160 - val_loss: 0.2938 - val_accuracy: 0.7727\n",
      "Epoch 858/1000\n",
      "614/614 [==============================] - 0s 266us/step - loss: 0.2561 - accuracy: 0.8046 - val_loss: 0.2898 - val_accuracy: 0.7727\n",
      "Epoch 859/1000\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.2530 - accuracy: 0.8160 - val_loss: 0.2813 - val_accuracy: 0.7922\n",
      "Epoch 860/1000\n",
      "614/614 [==============================] - 0s 247us/step - loss: 0.2519 - accuracy: 0.8160 - val_loss: 0.2881 - val_accuracy: 0.7792\n",
      "Epoch 861/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2512 - accuracy: 0.8160 - val_loss: 0.2894 - val_accuracy: 0.7727\n",
      "Epoch 862/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2514 - accuracy: 0.8111 - val_loss: 0.2827 - val_accuracy: 0.7857\n",
      "Epoch 863/1000\n",
      "614/614 [==============================] - 0s 243us/step - loss: 0.2522 - accuracy: 0.8208 - val_loss: 0.2839 - val_accuracy: 0.7922\n",
      "Epoch 864/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2523 - accuracy: 0.8078 - val_loss: 0.2913 - val_accuracy: 0.7597\n",
      "Epoch 865/1000\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.2519 - accuracy: 0.8176 - val_loss: 0.2895 - val_accuracy: 0.7922\n",
      "Epoch 866/1000\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.2517 - accuracy: 0.8176 - val_loss: 0.2872 - val_accuracy: 0.7727\n",
      "Epoch 867/1000\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.2512 - accuracy: 0.8176 - val_loss: 0.2891 - val_accuracy: 0.7792\n",
      "Epoch 868/1000\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.2520 - accuracy: 0.8143 - val_loss: 0.2816 - val_accuracy: 0.7987\n",
      "Epoch 869/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2532 - accuracy: 0.8062 - val_loss: 0.2797 - val_accuracy: 0.7922\n",
      "Epoch 870/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2564 - accuracy: 0.7997 - val_loss: 0.2866 - val_accuracy: 0.7727\n",
      "Epoch 871/1000\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.2524 - accuracy: 0.8094 - val_loss: 0.2896 - val_accuracy: 0.7792\n",
      "Epoch 872/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2528 - accuracy: 0.7932 - val_loss: 0.2916 - val_accuracy: 0.7727\n",
      "Epoch 873/1000\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.2545 - accuracy: 0.8208 - val_loss: 0.2785 - val_accuracy: 0.7857\n",
      "Epoch 874/1000\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.2620 - accuracy: 0.7997 - val_loss: 0.3434 - val_accuracy: 0.6299\n",
      "Epoch 875/1000\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.2667 - accuracy: 0.7720 - val_loss: 0.2770 - val_accuracy: 0.7857\n",
      "Epoch 876/1000\n",
      "614/614 [==============================] - 0s 273us/step - loss: 0.2578 - accuracy: 0.7948 - val_loss: 0.2935 - val_accuracy: 0.7727\n",
      "Epoch 877/1000\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.2541 - accuracy: 0.7997 - val_loss: 0.2950 - val_accuracy: 0.7662\n",
      "Epoch 878/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2533 - accuracy: 0.8160 - val_loss: 0.2791 - val_accuracy: 0.7857\n",
      "Epoch 879/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2537 - accuracy: 0.8029 - val_loss: 0.2899 - val_accuracy: 0.7597\n",
      "Epoch 880/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2515 - accuracy: 0.8111 - val_loss: 0.2900 - val_accuracy: 0.7792\n",
      "Epoch 881/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2527 - accuracy: 0.8078 - val_loss: 0.2795 - val_accuracy: 0.7857\n",
      "Epoch 882/1000\n",
      "614/614 [==============================] - 0s 277us/step - loss: 0.2520 - accuracy: 0.8062 - val_loss: 0.2969 - val_accuracy: 0.7662\n",
      "Epoch 883/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2506 - accuracy: 0.8143 - val_loss: 0.2843 - val_accuracy: 0.7857\n",
      "Epoch 884/1000\n",
      "614/614 [==============================] - 0s 300us/step - loss: 0.2511 - accuracy: 0.8176 - val_loss: 0.2825 - val_accuracy: 0.7922\n",
      "Epoch 885/1000\n",
      "614/614 [==============================] - 0s 253us/step - loss: 0.2538 - accuracy: 0.8127 - val_loss: 0.3012 - val_accuracy: 0.7403\n",
      "Epoch 886/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2518 - accuracy: 0.8062 - val_loss: 0.2828 - val_accuracy: 0.7857\n",
      "Epoch 887/1000\n",
      "614/614 [==============================] - 0s 251us/step - loss: 0.2512 - accuracy: 0.8127 - val_loss: 0.2828 - val_accuracy: 0.7857\n",
      "Epoch 888/1000\n",
      "614/614 [==============================] - 0s 248us/step - loss: 0.2530 - accuracy: 0.8127 - val_loss: 0.2868 - val_accuracy: 0.7792\n",
      "Epoch 889/1000\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.2509 - accuracy: 0.8143 - val_loss: 0.2963 - val_accuracy: 0.7597\n",
      "Epoch 890/1000\n",
      "614/614 [==============================] - 0s 247us/step - loss: 0.2550 - accuracy: 0.8078 - val_loss: 0.2891 - val_accuracy: 0.7792\n",
      "Epoch 891/1000\n",
      "614/614 [==============================] - 0s 293us/step - loss: 0.2505 - accuracy: 0.8225 - val_loss: 0.2805 - val_accuracy: 0.7922\n",
      "Epoch 892/1000\n",
      "614/614 [==============================] - 0s 248us/step - loss: 0.2533 - accuracy: 0.8029 - val_loss: 0.2864 - val_accuracy: 0.7857\n",
      "Epoch 893/1000\n",
      "614/614 [==============================] - 0s 247us/step - loss: 0.2552 - accuracy: 0.8013 - val_loss: 0.3001 - val_accuracy: 0.7532\n",
      "Epoch 894/1000\n",
      "614/614 [==============================] - 0s 275us/step - loss: 0.2535 - accuracy: 0.8094 - val_loss: 0.2901 - val_accuracy: 0.7792\n",
      "Epoch 895/1000\n",
      "614/614 [==============================] - 0s 259us/step - loss: 0.2526 - accuracy: 0.8062 - val_loss: 0.2901 - val_accuracy: 0.7727\n",
      "Epoch 896/1000\n",
      "614/614 [==============================] - 0s 243us/step - loss: 0.2538 - accuracy: 0.8029 - val_loss: 0.2795 - val_accuracy: 0.8117\n",
      "Epoch 897/1000\n",
      "614/614 [==============================] - 0s 265us/step - loss: 0.2509 - accuracy: 0.8143 - val_loss: 0.2942 - val_accuracy: 0.7662\n",
      "Epoch 898/1000\n",
      "614/614 [==============================] - 0s 243us/step - loss: 0.2497 - accuracy: 0.8160 - val_loss: 0.2837 - val_accuracy: 0.7922\n",
      "Epoch 899/1000\n",
      "614/614 [==============================] - 0s 261us/step - loss: 0.2506 - accuracy: 0.8143 - val_loss: 0.2887 - val_accuracy: 0.7922\n",
      "Epoch 900/1000\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.2525 - accuracy: 0.8078 - val_loss: 0.2867 - val_accuracy: 0.7662\n",
      "Epoch 901/1000\n",
      "614/614 [==============================] - 0s 248us/step - loss: 0.2506 - accuracy: 0.8160 - val_loss: 0.2914 - val_accuracy: 0.7792\n",
      "Epoch 902/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2515 - accuracy: 0.8143 - val_loss: 0.2801 - val_accuracy: 0.8052\n",
      "Epoch 903/1000\n",
      "614/614 [==============================] - 0s 248us/step - loss: 0.2521 - accuracy: 0.8127 - val_loss: 0.2944 - val_accuracy: 0.7532\n",
      "Epoch 904/1000\n",
      "614/614 [==============================] - 0s 243us/step - loss: 0.2509 - accuracy: 0.8094 - val_loss: 0.2898 - val_accuracy: 0.7792\n",
      "Epoch 905/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2507 - accuracy: 0.8176 - val_loss: 0.2919 - val_accuracy: 0.7857\n",
      "Epoch 906/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2498 - accuracy: 0.8257 - val_loss: 0.2827 - val_accuracy: 0.7922\n",
      "Epoch 907/1000\n",
      "614/614 [==============================] - 0s 251us/step - loss: 0.2505 - accuracy: 0.8225 - val_loss: 0.3032 - val_accuracy: 0.7532\n",
      "Epoch 908/1000\n",
      "614/614 [==============================] - 0s 243us/step - loss: 0.2538 - accuracy: 0.8029 - val_loss: 0.2764 - val_accuracy: 0.7922\n",
      "Epoch 909/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2557 - accuracy: 0.8062 - val_loss: 0.2916 - val_accuracy: 0.7727\n",
      "Epoch 910/1000\n",
      "614/614 [==============================] - 0s 247us/step - loss: 0.2512 - accuracy: 0.7980 - val_loss: 0.2872 - val_accuracy: 0.7857\n",
      "Epoch 911/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2501 - accuracy: 0.8094 - val_loss: 0.2905 - val_accuracy: 0.7792\n",
      "Epoch 912/1000\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.2498 - accuracy: 0.8160 - val_loss: 0.2847 - val_accuracy: 0.7792\n",
      "Epoch 913/1000\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.2512 - accuracy: 0.8143 - val_loss: 0.2996 - val_accuracy: 0.7532\n",
      "Epoch 914/1000\n",
      "614/614 [==============================] - 0s 261us/step - loss: 0.2524 - accuracy: 0.8143 - val_loss: 0.2869 - val_accuracy: 0.7922\n",
      "Epoch 915/1000\n",
      "614/614 [==============================] - 0s 270us/step - loss: 0.2524 - accuracy: 0.8208 - val_loss: 0.2788 - val_accuracy: 0.7922\n",
      "Epoch 916/1000\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.2532 - accuracy: 0.8078 - val_loss: 0.2867 - val_accuracy: 0.7662\n",
      "Epoch 917/1000\n",
      "614/614 [==============================] - 0s 243us/step - loss: 0.2500 - accuracy: 0.8111 - val_loss: 0.2881 - val_accuracy: 0.7792\n",
      "Epoch 918/1000\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.2507 - accuracy: 0.8127 - val_loss: 0.2790 - val_accuracy: 0.7922\n",
      "Epoch 919/1000\n",
      "614/614 [==============================] - 0s 256us/step - loss: 0.2527 - accuracy: 0.8013 - val_loss: 0.2843 - val_accuracy: 0.7857\n",
      "Epoch 920/1000\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.2493 - accuracy: 0.8111 - val_loss: 0.2897 - val_accuracy: 0.7727\n",
      "Epoch 921/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2500 - accuracy: 0.8208 - val_loss: 0.2936 - val_accuracy: 0.7597\n",
      "Epoch 922/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2496 - accuracy: 0.8225 - val_loss: 0.2896 - val_accuracy: 0.7857\n",
      "Epoch 923/1000\n",
      "614/614 [==============================] - 0s 281us/step - loss: 0.2499 - accuracy: 0.8274 - val_loss: 0.2790 - val_accuracy: 0.7987\n",
      "Epoch 924/1000\n",
      "614/614 [==============================] - 0s 278us/step - loss: 0.2519 - accuracy: 0.8094 - val_loss: 0.3025 - val_accuracy: 0.7403\n",
      "Epoch 925/1000\n",
      "614/614 [==============================] - 0s 256us/step - loss: 0.2532 - accuracy: 0.8111 - val_loss: 0.2788 - val_accuracy: 0.7922\n",
      "Epoch 926/1000\n",
      "614/614 [==============================] - 0s 255us/step - loss: 0.2533 - accuracy: 0.8094 - val_loss: 0.2863 - val_accuracy: 0.7792\n",
      "Epoch 927/1000\n",
      "614/614 [==============================] - 0s 243us/step - loss: 0.2518 - accuracy: 0.8046 - val_loss: 0.3033 - val_accuracy: 0.7468\n",
      "Epoch 928/1000\n",
      "614/614 [==============================] - 0s 273us/step - loss: 0.2561 - accuracy: 0.8127 - val_loss: 0.2832 - val_accuracy: 0.7857\n",
      "Epoch 929/1000\n",
      "614/614 [==============================] - 0s 257us/step - loss: 0.2527 - accuracy: 0.8257 - val_loss: 0.2810 - val_accuracy: 0.7922\n",
      "Epoch 930/1000\n",
      "614/614 [==============================] - 0s 253us/step - loss: 0.2570 - accuracy: 0.8029 - val_loss: 0.3034 - val_accuracy: 0.7403\n",
      "Epoch 931/1000\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.2523 - accuracy: 0.8013 - val_loss: 0.2836 - val_accuracy: 0.7857\n",
      "Epoch 932/1000\n",
      "614/614 [==============================] - 0s 247us/step - loss: 0.2502 - accuracy: 0.8208 - val_loss: 0.2836 - val_accuracy: 0.7792\n",
      "Epoch 933/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2492 - accuracy: 0.8143 - val_loss: 0.2891 - val_accuracy: 0.7857\n",
      "Epoch 934/1000\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.2492 - accuracy: 0.8160 - val_loss: 0.2835 - val_accuracy: 0.7922\n",
      "Epoch 935/1000\n",
      "614/614 [==============================] - 0s 248us/step - loss: 0.2488 - accuracy: 0.8241 - val_loss: 0.2902 - val_accuracy: 0.7662\n",
      "Epoch 936/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2492 - accuracy: 0.8176 - val_loss: 0.2871 - val_accuracy: 0.7987\n",
      "Epoch 937/1000\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.2496 - accuracy: 0.8225 - val_loss: 0.2921 - val_accuracy: 0.7597\n",
      "Epoch 938/1000\n",
      "614/614 [==============================] - 0s 255us/step - loss: 0.2505 - accuracy: 0.8143 - val_loss: 0.2823 - val_accuracy: 0.7857\n",
      "Epoch 939/1000\n",
      "614/614 [==============================] - 0s 256us/step - loss: 0.2493 - accuracy: 0.8241 - val_loss: 0.2860 - val_accuracy: 0.7922\n",
      "Epoch 940/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2484 - accuracy: 0.8143 - val_loss: 0.2943 - val_accuracy: 0.7532\n",
      "Epoch 941/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2497 - accuracy: 0.8274 - val_loss: 0.2779 - val_accuracy: 0.7987\n",
      "Epoch 942/1000\n",
      "614/614 [==============================] - 0s 251us/step - loss: 0.2563 - accuracy: 0.8013 - val_loss: 0.3046 - val_accuracy: 0.7403\n",
      "Epoch 943/1000\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.2576 - accuracy: 0.8029 - val_loss: 0.2968 - val_accuracy: 0.7597\n",
      "Epoch 944/1000\n",
      "614/614 [==============================] - 0s 267us/step - loss: 0.2579 - accuracy: 0.8029 - val_loss: 0.2751 - val_accuracy: 0.7987\n",
      "Epoch 945/1000\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.2546 - accuracy: 0.8094 - val_loss: 0.3035 - val_accuracy: 0.7532\n",
      "Epoch 946/1000\n",
      "614/614 [==============================] - 0s 262us/step - loss: 0.2527 - accuracy: 0.8160 - val_loss: 0.2803 - val_accuracy: 0.7922\n",
      "Epoch 947/1000\n",
      "614/614 [==============================] - 0s 271us/step - loss: 0.2516 - accuracy: 0.8208 - val_loss: 0.2859 - val_accuracy: 0.7987\n",
      "Epoch 948/1000\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.2538 - accuracy: 0.8078 - val_loss: 0.3039 - val_accuracy: 0.7468\n",
      "Epoch 949/1000\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.2514 - accuracy: 0.8160 - val_loss: 0.2844 - val_accuracy: 0.7792\n",
      "Epoch 950/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2492 - accuracy: 0.8225 - val_loss: 0.2837 - val_accuracy: 0.7922\n",
      "Epoch 951/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2488 - accuracy: 0.8078 - val_loss: 0.2987 - val_accuracy: 0.7662\n",
      "Epoch 952/1000\n",
      "614/614 [==============================] - 0s 248us/step - loss: 0.2500 - accuracy: 0.8062 - val_loss: 0.2808 - val_accuracy: 0.7987\n",
      "Epoch 953/1000\n",
      "614/614 [==============================] - 0s 253us/step - loss: 0.2490 - accuracy: 0.8160 - val_loss: 0.2900 - val_accuracy: 0.7792\n",
      "Epoch 954/1000\n",
      "614/614 [==============================] - 0s 243us/step - loss: 0.2480 - accuracy: 0.8160 - val_loss: 0.2846 - val_accuracy: 0.7857\n",
      "Epoch 955/1000\n",
      "614/614 [==============================] - 0s 255us/step - loss: 0.2478 - accuracy: 0.8225 - val_loss: 0.2926 - val_accuracy: 0.7662\n",
      "Epoch 956/1000\n",
      "614/614 [==============================] - 0s 272us/step - loss: 0.2486 - accuracy: 0.8192 - val_loss: 0.2812 - val_accuracy: 0.7922\n",
      "Epoch 957/1000\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.2480 - accuracy: 0.8192 - val_loss: 0.3036 - val_accuracy: 0.7403\n",
      "Epoch 958/1000\n",
      "614/614 [==============================] - 0s 261us/step - loss: 0.2478 - accuracy: 0.8322 - val_loss: 0.2798 - val_accuracy: 0.7792\n",
      "Epoch 959/1000\n",
      "614/614 [==============================] - 0s 266us/step - loss: 0.2585 - accuracy: 0.8029 - val_loss: 0.2872 - val_accuracy: 0.7922\n",
      "Epoch 960/1000\n",
      "614/614 [==============================] - 0s 304us/step - loss: 0.2505 - accuracy: 0.8013 - val_loss: 0.2906 - val_accuracy: 0.7727\n",
      "Epoch 961/1000\n",
      "614/614 [==============================] - 0s 277us/step - loss: 0.2475 - accuracy: 0.8225 - val_loss: 0.2821 - val_accuracy: 0.7857\n",
      "Epoch 962/1000\n",
      "614/614 [==============================] - 0s 282us/step - loss: 0.2473 - accuracy: 0.8290 - val_loss: 0.2943 - val_accuracy: 0.7597\n",
      "Epoch 963/1000\n",
      "614/614 [==============================] - 0s 287us/step - loss: 0.2495 - accuracy: 0.8176 - val_loss: 0.2853 - val_accuracy: 0.7987\n",
      "Epoch 964/1000\n",
      "614/614 [==============================] - 0s 261us/step - loss: 0.2486 - accuracy: 0.8257 - val_loss: 0.2884 - val_accuracy: 0.7662\n",
      "Epoch 965/1000\n",
      "614/614 [==============================] - 0s 282us/step - loss: 0.2481 - accuracy: 0.8225 - val_loss: 0.3024 - val_accuracy: 0.7403\n",
      "Epoch 966/1000\n",
      "614/614 [==============================] - 0s 264us/step - loss: 0.2519 - accuracy: 0.8127 - val_loss: 0.2831 - val_accuracy: 0.7857\n",
      "Epoch 967/1000\n",
      "614/614 [==============================] - 0s 269us/step - loss: 0.2495 - accuracy: 0.8127 - val_loss: 0.2858 - val_accuracy: 0.7662\n",
      "Epoch 968/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2480 - accuracy: 0.8225 - val_loss: 0.2974 - val_accuracy: 0.7468\n",
      "Epoch 969/1000\n",
      "614/614 [==============================] - 0s 262us/step - loss: 0.2478 - accuracy: 0.8111 - val_loss: 0.2814 - val_accuracy: 0.7922\n",
      "Epoch 970/1000\n",
      "614/614 [==============================] - 0s 288us/step - loss: 0.2487 - accuracy: 0.8306 - val_loss: 0.2860 - val_accuracy: 0.7857\n",
      "Epoch 971/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2473 - accuracy: 0.8176 - val_loss: 0.2809 - val_accuracy: 0.8052\n",
      "Epoch 972/1000\n",
      "614/614 [==============================] - 0s 274us/step - loss: 0.2488 - accuracy: 0.8143 - val_loss: 0.2899 - val_accuracy: 0.7662\n",
      "Epoch 973/1000\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.2488 - accuracy: 0.8127 - val_loss: 0.2866 - val_accuracy: 0.7922\n",
      "Epoch 974/1000\n",
      "614/614 [==============================] - 0s 265us/step - loss: 0.2482 - accuracy: 0.8257 - val_loss: 0.2796 - val_accuracy: 0.7987\n",
      "Epoch 975/1000\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.2534 - accuracy: 0.8127 - val_loss: 0.2956 - val_accuracy: 0.7597\n",
      "Epoch 976/1000\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.2539 - accuracy: 0.8241 - val_loss: 0.3016 - val_accuracy: 0.7403\n",
      "Epoch 977/1000\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.2505 - accuracy: 0.8208 - val_loss: 0.2784 - val_accuracy: 0.7987\n",
      "Epoch 978/1000\n",
      "614/614 [==============================] - 0s 259us/step - loss: 0.2491 - accuracy: 0.8176 - val_loss: 0.2869 - val_accuracy: 0.7922\n",
      "Epoch 979/1000\n",
      "614/614 [==============================] - 0s 258us/step - loss: 0.2496 - accuracy: 0.8192 - val_loss: 0.2977 - val_accuracy: 0.7532\n",
      "Epoch 980/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2529 - accuracy: 0.8078 - val_loss: 0.2934 - val_accuracy: 0.7662\n",
      "Epoch 981/1000\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.2492 - accuracy: 0.8290 - val_loss: 0.2838 - val_accuracy: 0.7857\n",
      "Epoch 982/1000\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.2480 - accuracy: 0.8192 - val_loss: 0.2906 - val_accuracy: 0.7792\n",
      "Epoch 983/1000\n",
      "614/614 [==============================] - 0s 251us/step - loss: 0.2471 - accuracy: 0.8257 - val_loss: 0.2873 - val_accuracy: 0.7727\n",
      "Epoch 984/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2474 - accuracy: 0.8241 - val_loss: 0.2815 - val_accuracy: 0.7922\n",
      "Epoch 985/1000\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.2470 - accuracy: 0.8241 - val_loss: 0.2934 - val_accuracy: 0.7597\n",
      "Epoch 986/1000\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.2482 - accuracy: 0.8306 - val_loss: 0.2861 - val_accuracy: 0.7662\n",
      "Epoch 987/1000\n",
      "614/614 [==============================] - 0s 273us/step - loss: 0.2477 - accuracy: 0.8241 - val_loss: 0.2819 - val_accuracy: 0.7792\n",
      "Epoch 988/1000\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.2481 - accuracy: 0.8078 - val_loss: 0.3022 - val_accuracy: 0.7403\n",
      "Epoch 989/1000\n",
      "614/614 [==============================] - 0s 257us/step - loss: 0.2502 - accuracy: 0.8094 - val_loss: 0.2829 - val_accuracy: 0.7857\n",
      "Epoch 990/1000\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2467 - accuracy: 0.8241 - val_loss: 0.2859 - val_accuracy: 0.7727\n",
      "Epoch 991/1000\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.2463 - accuracy: 0.8322 - val_loss: 0.2892 - val_accuracy: 0.7922\n",
      "Epoch 992/1000\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.2465 - accuracy: 0.8290 - val_loss: 0.2835 - val_accuracy: 0.7922\n",
      "Epoch 993/1000\n",
      "614/614 [==============================] - 0s 441us/step - loss: 0.2476 - accuracy: 0.8306 - val_loss: 0.2806 - val_accuracy: 0.7987\n",
      "Epoch 994/1000\n",
      "614/614 [==============================] - 0s 482us/step - loss: 0.2493 - accuracy: 0.8160 - val_loss: 0.2886 - val_accuracy: 0.7792\n",
      "Epoch 995/1000\n",
      "614/614 [==============================] - 0s 306us/step - loss: 0.2456 - accuracy: 0.8274 - val_loss: 0.2846 - val_accuracy: 0.7792\n",
      "Epoch 996/1000\n",
      "614/614 [==============================] - 0s 357us/step - loss: 0.2467 - accuracy: 0.8143 - val_loss: 0.2926 - val_accuracy: 0.7597\n",
      "Epoch 997/1000\n",
      "614/614 [==============================] - 0s 504us/step - loss: 0.2464 - accuracy: 0.8257 - val_loss: 0.2839 - val_accuracy: 0.7922\n",
      "Epoch 998/1000\n",
      "614/614 [==============================] - 0s 350us/step - loss: 0.2473 - accuracy: 0.8241 - val_loss: 0.3003 - val_accuracy: 0.7403\n",
      "Epoch 999/1000\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.2486 - accuracy: 0.8192 - val_loss: 0.2873 - val_accuracy: 0.7662\n",
      "Epoch 1000/1000\n",
      "614/614 [==============================] - 0s 276us/step - loss: 0.2461 - accuracy: 0.8388 - val_loss: 0.2801 - val_accuracy: 0.7987\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=8, activation='sigmoid',kernel_regularizer=l1(0.0001),bias_regularizer=l1(0.0001),activity_regularizer=l1(0.0001)))\n",
    "model.add(Dense(100, activation='sigmoid', kernel_regularizer=l1(0.0001),bias_regularizer=l1(0.0001),activity_regularizer=l1(0.0001)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "history=model.fit(X_train,y_train, epochs=1000, batch_size=70, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 500)               4500      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 54,802\n",
      "Trainable params: 54,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 0.8159608840942383\n",
      "Testing Accuracy : 0.798701286315918\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_,train_acc =model.evaluate(X_train,y_train,verbose=0)\n",
    "_,test_acc  =model.evaluate(X_test,y_test, verbose=0)\n",
    "print('Training Accuracy :',train_acc)\n",
    "print('Testing Accuracy :',test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict classes for test set\n",
    "yhat_classes = model.predict_classes(X_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_classes=list(yhat_classes)\n",
    "#yhat_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we had done one hot encoding of the target feature.\n",
    "#We now convert it back to its original form for compatibility.\n",
    "y_test2=y_test.tolist()\n",
    "y_test3=[]\n",
    "for i in y_test2:\n",
    "    if(i[0]=='0.0'):\n",
    "        y_test3.append(1)\n",
    "    else:\n",
    "        y_test3.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: %f 0.7987012987012987\n"
     ]
    }
   ],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test3, yhat_classes)\n",
    "print('Accuracy: %f',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.697674\n"
     ]
    }
   ],
   "source": [
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test3, yhat_classes)\n",
    "print('Precision: %f'%precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.625000\n"
     ]
    }
   ],
   "source": [
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test3, yhat_classes)\n",
    "print('Recall: %f'%recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.659341\n"
     ]
    }
   ],
   "source": [
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test3, yhat_classes)\n",
    "print('F1 score: %f'%f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       106\n",
      "           1       0.70      0.62      0.66        48\n",
      "\n",
      "    accuracy                           0.80       154\n",
      "   macro avg       0.77      0.75      0.76       154\n",
      "weighted avg       0.79      0.80      0.80       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test3, yhat_classes, target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
